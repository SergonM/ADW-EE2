[0m11:19:53.723466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e682e59a120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e682c4bd590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e682c4bd450>]}


============================== 11:19:53.727577 | 49b655a4-7c58-433c-a57f-bb82a6295dc4 ==============================
[0m11:19:53.727577 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:19:53.728271 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/logs', 'version_check': 'True', 'profiles_dir': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m11:19:53.738881 [info ] [MainThread]: dbt version: 1.8.9
[0m11:19:53.739413 [info ] [MainThread]: python version: 3.13.2
[0m11:19:53.739836 [info ] [MainThread]: python path: /home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/env/bin/python
[0m11:19:53.740250 [info ] [MainThread]: os info: Linux-6.14.2-arch1-1-x86_64-with-glibc2.41
[0m11:19:53.827542 [info ] [MainThread]: Using profiles dir at /home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar
[0m11:19:53.828064 [info ] [MainThread]: Using profiles.yml file at /home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/profiles.yml
[0m11:19:53.828498 [info ] [MainThread]: Using dbt_project.yml file at /home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/dbt_project.yml
[0m11:19:53.829113 [info ] [MainThread]: adapter type: clickhouse
[0m11:19:53.829544 [info ] [MainThread]: adapter version: 1.8.9
[0m11:19:53.955486 [info ] [MainThread]: Configuration:
[0m11:19:53.956031 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m11:19:53.956485 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m11:19:53.956919 [info ] [MainThread]: Required dependencies:
[0m11:19:53.957490 [debug] [MainThread]: Executing "git --help"
[0m11:19:53.965451 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m11:19:53.966096 [debug] [MainThread]: STDERR: "b''"
[0m11:19:53.966513 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m11:19:53.966958 [info ] [MainThread]: Connection:
[0m11:19:53.967438 [info ] [MainThread]:   driver: None
[0m11:19:53.967957 [info ] [MainThread]:   host: localhost
[0m11:19:53.968487 [info ] [MainThread]:   port: 9000
[0m11:19:53.968907 [info ] [MainThread]:   user: user
[0m11:19:53.969321 [info ] [MainThread]:   schema: adw02_stag
[0m11:19:53.969756 [info ] [MainThread]:   retries: 1
[0m11:19:53.970181 [info ] [MainThread]:   database_engine: None
[0m11:19:53.970624 [info ] [MainThread]:   cluster_mode: False
[0m11:19:53.971050 [info ] [MainThread]:   secure: False
[0m11:19:53.971496 [info ] [MainThread]:   verify: True
[0m11:19:53.971908 [info ] [MainThread]:   client_cert: None
[0m11:19:53.972323 [info ] [MainThread]:   client_cert_key: None
[0m11:19:53.972803 [info ] [MainThread]:   connect_timeout: 10
[0m11:19:53.973227 [info ] [MainThread]:   send_receive_timeout: 300
[0m11:19:53.973688 [info ] [MainThread]:   sync_request_timeout: 5
[0m11:19:53.974263 [info ] [MainThread]:   compress_block_size: 1048576
[0m11:19:53.974882 [info ] [MainThread]:   compression: 
[0m11:19:53.975629 [info ] [MainThread]:   check_exchange: True
[0m11:19:53.976413 [info ] [MainThread]:   custom_settings: None
[0m11:19:53.977201 [info ] [MainThread]:   use_lw_deletes: False
[0m11:19:53.977912 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m11:19:53.978630 [info ] [MainThread]:   tcp_keepalive: False
[0m11:19:53.979227 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:19:54.078155 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m11:19:54.078676 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:19:54.368156 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m11:19:54.371465 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:19:54.402388 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m11:19:54.402900 [info ] [MainThread]: [32mAll checks passed![0m
[0m11:19:54.404387 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.7492501, "process_in_blocks": "3472", "process_kernel_time": 0.197622, "process_mem_max_rss": "132624", "process_out_blocks": "24", "process_user_time": 2.230371}
[0m11:19:54.404994 [debug] [MainThread]: Command `dbt debug` succeeded at 11:19:54.404837 after 0.75 seconds
[0m11:19:54.405465 [debug] [MainThread]: Connection 'debug' was left open.
[0m11:19:54.406003 [debug] [MainThread]: On debug: Close
[0m11:19:54.406622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e682c246780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e682a949010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7e682c1ef570>]}
[0m11:19:54.407367 [debug] [MainThread]: Flushing usage events
[0m11:27:10.145327 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d15428a120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d152199590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d152199450>]}


============================== 11:27:10.149314 | 1edcedd1-faee-4714-b394-7496813c691a ==============================
[0m11:27:10.149314 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:27:10.150022 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'profiles_dir': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar', 'log_path': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/logs', 'debug': 'False', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'no_print': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt debug', 'introspect': 'True', 'log_format': 'default', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:27:10.161357 [info ] [MainThread]: dbt version: 1.8.9
[0m11:27:10.161885 [info ] [MainThread]: python version: 3.13.2
[0m11:27:10.162316 [info ] [MainThread]: python path: /home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/env/bin/python
[0m11:27:10.162749 [info ] [MainThread]: os info: Linux-6.14.2-arch1-1-x86_64-with-glibc2.41
[0m11:27:10.251743 [info ] [MainThread]: Using profiles dir at /home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar
[0m11:27:10.252267 [info ] [MainThread]: Using profiles.yml file at /home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/profiles.yml
[0m11:27:10.252702 [info ] [MainThread]: Using dbt_project.yml file at /home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/dbt_project.yml
[0m11:27:10.253315 [info ] [MainThread]: adapter type: clickhouse
[0m11:27:10.253746 [info ] [MainThread]: adapter version: 1.8.9
[0m11:27:10.384465 [info ] [MainThread]: Configuration:
[0m11:27:10.384990 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m11:27:10.385423 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m11:27:10.385835 [info ] [MainThread]: Required dependencies:
[0m11:27:10.386268 [debug] [MainThread]: Executing "git --help"
[0m11:27:10.388622 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m11:27:10.389280 [debug] [MainThread]: STDERR: "b''"
[0m11:27:10.389736 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m11:27:10.390175 [info ] [MainThread]: Connection:
[0m11:27:10.390623 [info ] [MainThread]:   driver: None
[0m11:27:10.391028 [info ] [MainThread]:   host: localhost
[0m11:27:10.391494 [info ] [MainThread]:   port: 9000
[0m11:27:10.391891 [info ] [MainThread]:   user: user
[0m11:27:10.392286 [info ] [MainThread]:   schema: adw02_stag
[0m11:27:10.392701 [info ] [MainThread]:   retries: 1
[0m11:27:10.393096 [info ] [MainThread]:   database_engine: None
[0m11:27:10.393505 [info ] [MainThread]:   cluster_mode: False
[0m11:27:10.393900 [info ] [MainThread]:   secure: False
[0m11:27:10.394290 [info ] [MainThread]:   verify: True
[0m11:27:10.394710 [info ] [MainThread]:   client_cert: None
[0m11:27:10.395181 [info ] [MainThread]:   client_cert_key: None
[0m11:27:10.395656 [info ] [MainThread]:   connect_timeout: 10
[0m11:27:10.396054 [info ] [MainThread]:   send_receive_timeout: 300
[0m11:27:10.396489 [info ] [MainThread]:   sync_request_timeout: 5
[0m11:27:10.396901 [info ] [MainThread]:   compress_block_size: 1048576
[0m11:27:10.397414 [info ] [MainThread]:   compression: 
[0m11:27:10.397821 [info ] [MainThread]:   check_exchange: True
[0m11:27:10.398211 [info ] [MainThread]:   custom_settings: None
[0m11:27:10.398619 [info ] [MainThread]:   use_lw_deletes: False
[0m11:27:10.399012 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m11:27:10.399485 [info ] [MainThread]:   tcp_keepalive: False
[0m11:27:10.400047 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:27:10.493603 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m11:27:10.494105 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:27:10.773611 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m11:27:10.776928 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:27:10.808631 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m11:27:10.809152 [info ] [MainThread]: [32mAll checks passed![0m
[0m11:27:10.810173 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.72756296, "process_in_blocks": "0", "process_kernel_time": 0.163228, "process_mem_max_rss": "132588", "process_out_blocks": "16", "process_user_time": 2.225012}
[0m11:27:10.810770 [debug] [MainThread]: Command `dbt debug` succeeded at 11:27:10.810622 after 0.73 seconds
[0m11:27:10.811201 [debug] [MainThread]: Connection 'debug' was left open.
[0m11:27:10.811654 [debug] [MainThread]: On debug: Close
[0m11:27:10.812223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d151f22780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d150625010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x78d151ecb790>]}
[0m11:27:10.812876 [debug] [MainThread]: Flushing usage events
[0m11:27:26.436076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7986b9692120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7986b75b1590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7986b75b1450>]}


============================== 11:27:26.440117 | 5ad42029-398b-430b-a743-6e39e5a162f9 ==============================
[0m11:27:26.440117 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:27:26.440980 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar', 'debug': 'False', 'fail_fast': 'False', 'log_path': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/logs', 'warn_error': 'None', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt debug', 'send_anonymous_usage_stats': 'True'}
[0m11:27:26.451869 [info ] [MainThread]: dbt version: 1.8.9
[0m11:27:26.452464 [info ] [MainThread]: python version: 3.13.2
[0m11:27:26.453085 [info ] [MainThread]: python path: /home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/env/bin/python
[0m11:27:26.453687 [info ] [MainThread]: os info: Linux-6.14.2-arch1-1-x86_64-with-glibc2.41
[0m11:27:26.540572 [info ] [MainThread]: Using profiles dir at /home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar
[0m11:27:26.541133 [info ] [MainThread]: Using profiles.yml file at /home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/profiles.yml
[0m11:27:26.541765 [info ] [MainThread]: Using dbt_project.yml file at /home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/dbt_project.yml
[0m11:27:26.542546 [info ] [MainThread]: adapter type: clickhouse
[0m11:27:26.542985 [info ] [MainThread]: adapter version: 1.8.9
[0m11:27:26.670004 [info ] [MainThread]: Configuration:
[0m11:27:26.670611 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m11:27:26.671248 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m11:27:26.671823 [info ] [MainThread]: Required dependencies:
[0m11:27:26.672414 [debug] [MainThread]: Executing "git --help"
[0m11:27:26.674838 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m11:27:26.675462 [debug] [MainThread]: STDERR: "b''"
[0m11:27:26.675866 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m11:27:26.676309 [info ] [MainThread]: Connection:
[0m11:27:26.676771 [info ] [MainThread]:   driver: None
[0m11:27:26.677184 [info ] [MainThread]:   host: localhost
[0m11:27:26.677602 [info ] [MainThread]:   port: 9000
[0m11:27:26.678024 [info ] [MainThread]:   user: user
[0m11:27:26.678579 [info ] [MainThread]:   schema: adw02_stag
[0m11:27:26.678997 [info ] [MainThread]:   retries: 1
[0m11:27:26.679426 [info ] [MainThread]:   database_engine: None
[0m11:27:26.679850 [info ] [MainThread]:   cluster_mode: False
[0m11:27:26.680496 [info ] [MainThread]:   secure: False
[0m11:27:26.680906 [info ] [MainThread]:   verify: True
[0m11:27:26.681301 [info ] [MainThread]:   client_cert: None
[0m11:27:26.681721 [info ] [MainThread]:   client_cert_key: None
[0m11:27:26.682114 [info ] [MainThread]:   connect_timeout: 10
[0m11:27:26.682538 [info ] [MainThread]:   send_receive_timeout: 300
[0m11:27:26.682931 [info ] [MainThread]:   sync_request_timeout: 5
[0m11:27:26.683324 [info ] [MainThread]:   compress_block_size: 1048576
[0m11:27:26.683737 [info ] [MainThread]:   compression: 
[0m11:27:26.684131 [info ] [MainThread]:   check_exchange: True
[0m11:27:26.684561 [info ] [MainThread]:   custom_settings: None
[0m11:27:26.684980 [info ] [MainThread]:   use_lw_deletes: False
[0m11:27:26.685435 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m11:27:26.685857 [info ] [MainThread]:   tcp_keepalive: False
[0m11:27:26.686575 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:27:26.782539 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m11:27:26.783047 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:27:27.089411 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m11:27:27.092807 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:27:27.126840 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m11:27:27.127523 [info ] [MainThread]: [32mAll checks passed![0m
[0m11:27:27.128788 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.75395703, "process_in_blocks": "0", "process_kernel_time": 0.177794, "process_mem_max_rss": "132580", "process_out_blocks": "8", "process_user_time": 2.228099}
[0m11:27:27.129735 [debug] [MainThread]: Command `dbt debug` succeeded at 11:27:27.129523 after 0.76 seconds
[0m11:27:27.130380 [debug] [MainThread]: Connection 'debug' was left open.
[0m11:27:27.130864 [debug] [MainThread]: On debug: Close
[0m11:27:27.131619 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7986b733a780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7986b5a41010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7986b72e3790>]}
[0m11:27:27.132549 [debug] [MainThread]: Flushing usage events
[0m11:34:24.996640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7268e986e120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7268e7781590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7268e7781450>]}


============================== 11:34:25.000596 | 391f221c-d0b8-488b-aeac-b9da81f75a30 ==============================
[0m11:34:25.000596 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:34:25.001311 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar', 'debug': 'False', 'warn_error': 'None', 'log_path': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/logs', 'version_check': 'True', 'fail_fast': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'invocation_command': 'dbt debug', 'introspect': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:34:25.012019 [info ] [MainThread]: dbt version: 1.8.9
[0m11:34:25.012557 [info ] [MainThread]: python version: 3.13.2
[0m11:34:25.012977 [info ] [MainThread]: python path: /home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/env/bin/python
[0m11:34:25.013399 [info ] [MainThread]: os info: Linux-6.14.2-arch1-1-x86_64-with-glibc2.41
[0m11:34:25.102153 [info ] [MainThread]: Using profiles dir at /home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar
[0m11:34:25.102690 [info ] [MainThread]: Using profiles.yml file at /home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/profiles.yml
[0m11:34:25.103111 [info ] [MainThread]: Using dbt_project.yml file at /home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/dbt_project.yml
[0m11:34:25.103721 [info ] [MainThread]: adapter type: clickhouse
[0m11:34:25.104196 [info ] [MainThread]: adapter version: 1.8.9
[0m11:34:25.231015 [info ] [MainThread]: Configuration:
[0m11:34:25.231573 [info ] [MainThread]:   profiles.yml file [[32mOK found and valid[0m]
[0m11:34:25.232011 [info ] [MainThread]:   dbt_project.yml file [[32mOK found and valid[0m]
[0m11:34:25.232451 [info ] [MainThread]: Required dependencies:
[0m11:34:25.232899 [debug] [MainThread]: Executing "git --help"
[0m11:34:25.235312 [debug] [MainThread]: STDOUT: "b"usage: git [-v | --version] [-h | --help] [-C <path>] [-c <name>=<value>]\n           [--exec-path[=<path>]] [--html-path] [--man-path] [--info-path]\n           [-p | --paginate | -P | --no-pager] [--no-replace-objects] [--no-lazy-fetch]\n           [--no-optional-locks] [--no-advice] [--bare] [--git-dir=<path>]\n           [--work-tree=<path>] [--namespace=<name>] [--config-env=<name>=<envvar>]\n           <command> [<args>]\n\nThese are common Git commands used in various situations:\n\nstart a working area (see also: git help tutorial)\n   clone      Clone a repository into a new directory\n   init       Create an empty Git repository or reinitialize an existing one\n\nwork on the current change (see also: git help everyday)\n   add        Add file contents to the index\n   mv         Move or rename a file, a directory, or a symlink\n   restore    Restore working tree files\n   rm         Remove files from the working tree and from the index\n\nexamine the history and state (see also: git help revisions)\n   bisect     Use binary search to find the commit that introduced a bug\n   diff       Show changes between commits, commit and working tree, etc\n   grep       Print lines matching a pattern\n   log        Show commit logs\n   show       Show various types of objects\n   status     Show the working tree status\n\ngrow, mark and tweak your common history\n   backfill   Download missing objects in a partial clone\n   branch     List, create, or delete branches\n   commit     Record changes to the repository\n   merge      Join two or more development histories together\n   rebase     Reapply commits on top of another base tip\n   reset      Reset current HEAD to the specified state\n   switch     Switch branches\n   tag        Create, list, delete or verify a tag object signed with GPG\n\ncollaborate (see also: git help workflows)\n   fetch      Download objects and refs from another repository\n   pull       Fetch from and integrate with another repository or a local branch\n   push       Update remote refs along with associated objects\n\n'git help -a' and 'git help -g' list available subcommands and some\nconcept guides. See 'git help <command>' or 'git help <concept>'\nto read about a specific subcommand or concept.\nSee 'git help git' for an overview of the system.\n""
[0m11:34:25.235936 [debug] [MainThread]: STDERR: "b''"
[0m11:34:25.236550 [info ] [MainThread]:  - git [[32mOK found[0m]

[0m11:34:25.237005 [info ] [MainThread]: Connection:
[0m11:34:25.237481 [info ] [MainThread]:   driver: None
[0m11:34:25.237914 [info ] [MainThread]:   host: localhost
[0m11:34:25.238329 [info ] [MainThread]:   port: 9000
[0m11:34:25.238757 [info ] [MainThread]:   user: user
[0m11:34:25.239165 [info ] [MainThread]:   schema: adw02_stag
[0m11:34:25.239622 [info ] [MainThread]:   retries: 1
[0m11:34:25.240036 [info ] [MainThread]:   database_engine: None
[0m11:34:25.240459 [info ] [MainThread]:   cluster_mode: False
[0m11:34:25.240985 [info ] [MainThread]:   secure: False
[0m11:34:25.241403 [info ] [MainThread]:   verify: True
[0m11:34:25.241813 [info ] [MainThread]:   client_cert: None
[0m11:34:25.242228 [info ] [MainThread]:   client_cert_key: None
[0m11:34:25.242655 [info ] [MainThread]:   connect_timeout: 10
[0m11:34:25.243062 [info ] [MainThread]:   send_receive_timeout: 300
[0m11:34:25.243584 [info ] [MainThread]:   sync_request_timeout: 5
[0m11:34:25.244001 [info ] [MainThread]:   compress_block_size: 1048576
[0m11:34:25.244424 [info ] [MainThread]:   compression: 
[0m11:34:25.245022 [info ] [MainThread]:   check_exchange: True
[0m11:34:25.245455 [info ] [MainThread]:   custom_settings: None
[0m11:34:25.245870 [info ] [MainThread]:   use_lw_deletes: False
[0m11:34:25.246281 [info ] [MainThread]:   allow_automatic_deduplication: False
[0m11:34:25.246724 [info ] [MainThread]:   tcp_keepalive: False
[0m11:34:25.247370 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:34:25.345166 [debug] [MainThread]: Acquiring new clickhouse connection 'debug'
[0m11:34:25.345684 [debug] [MainThread]: Opening a new connection, currently in state init
[0m11:34:25.627615 [debug] [MainThread]: dbt_clickhouse adapter: On debug: select 1 as id...
[0m11:34:25.630850 [debug] [MainThread]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:34:25.660755 [info ] [MainThread]:   Connection test: [[32mOK connection ok[0m]

[0m11:34:25.661279 [info ] [MainThread]: [32mAll checks passed![0m
[0m11:34:25.662256 [debug] [MainThread]: Resource report: {"command_name": "debug", "command_success": true, "command_wall_clock_time": 0.7305293, "process_in_blocks": "0", "process_kernel_time": 0.176712, "process_mem_max_rss": "132864", "process_out_blocks": "16", "process_user_time": 2.196322}
[0m11:34:25.662854 [debug] [MainThread]: Command `dbt debug` succeeded at 11:34:25.662697 after 0.73 seconds
[0m11:34:25.663287 [debug] [MainThread]: Connection 'debug' was left open.
[0m11:34:25.663758 [debug] [MainThread]: On debug: Close
[0m11:34:25.664370 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7268e7516780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7268e5c29010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7268e74bf790>]}
[0m11:34:25.665111 [debug] [MainThread]: Flushing usage events
[0m11:34:31.077293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a74aa8e120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a7489ad590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a7489ad450>]}


============================== 11:34:31.081338 | 3080f226-08e0-40d6-b6c3-393d9f8392e4 ==============================
[0m11:34:31.081338 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:34:31.082028 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/logs', 'version_check': 'True', 'profiles_dir': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'invocation_command': 'dbt run', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:34:31.300238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '3080f226-08e0-40d6-b6c3-393d9f8392e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a7499e1cd0>]}
[0m11:34:31.375504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '3080f226-08e0-40d6-b6c3-393d9f8392e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a74881f790>]}
[0m11:34:31.376371 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:34:31.499851 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:34:31.500795 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m11:34:31.501269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3080f226-08e0-40d6-b6c3-393d9f8392e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a7487f4850>]}
[0m11:34:33.492725 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m11:34:33.493375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '3080f226-08e0-40d6-b6c3-393d9f8392e4', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a748800320>]}
[0m11:34:33.772338 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.sakstar.marts
[0m11:34:33.786410 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3080f226-08e0-40d6-b6c3-393d9f8392e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a748337af0>]}
[0m11:34:33.921542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3080f226-08e0-40d6-b6c3-393d9f8392e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a748517860>]}
[0m11:34:33.922200 [info ] [MainThread]: Found 1 model, 2 data tests, 10 sources, 608 macros
[0m11:34:33.922725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3080f226-08e0-40d6-b6c3-393d9f8392e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a746a98590>]}
[0m11:34:33.925385 [info ] [MainThread]: 
[0m11:34:33.926241 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:34:33.927689 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:34:33.941085 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:34:34.230330 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:34:34.233828 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:34:34.266171 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__adw02_stag)
[0m11:34:34.274130 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw02_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw02_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw02_stag'
      

  ...
[0m11:34:34.291469 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:34:34.293528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3080f226-08e0-40d6-b6c3-393d9f8392e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a744d2aba0>]}
[0m11:34:34.294246 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m11:34:34.294788 [info ] [MainThread]: 
[0m11:34:34.303735 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m11:34:34.304518 [info ] [Thread-1 (]: 1 of 1 START sql table model `adw02_stag`.`stg_customer` ....................... [RUN]
[0m11:34:34.305133 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw02_stag, now model.sakstar.stg_customer)
[0m11:34:34.305639 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m11:34:34.314999 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m11:34:34.315986 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m11:34:34.349789 [debug] [Thread-1 (]: Creating new relation stg_customer
[0m11:34:34.396406 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

            

    
        create table `adw02_stag`.`stg_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
          )
        
        ...
[0m11:34:34.422513 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m11:34:34.446728 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

    select name, type from system.columns where table = 'stg_customer'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:34:34.451640 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:34:34.457985 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m11:34:34.459031 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_customer`
        ("customer_key", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_created", "customer_address", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_last_update", "c.address_id", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
  ...
[0m11:34:34.540198 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.08 seconds
[0m11:34:34.569483 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3080f226-08e0-40d6-b6c3-393d9f8392e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a7492fcf50>]}
[0m11:34:34.570364 [info ] [Thread-1 (]: 1 of 1 OK created sql table model `adw02_stag`.`stg_customer` .................. [[32mOK[0m in 0.26s]
[0m11:34:34.571206 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m11:34:34.572864 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:34:34.573296 [debug] [MainThread]: Connection 'model.sakstar.stg_customer' was left open.
[0m11:34:34.573962 [debug] [MainThread]: On model.sakstar.stg_customer: Close
[0m11:34:34.574605 [info ] [MainThread]: 
[0m11:34:34.575188 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.65 seconds (0.65s).
[0m11:34:34.576125 [debug] [MainThread]: Command end result
[0m11:34:34.624335 [info ] [MainThread]: 
[0m11:34:34.624950 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:34:34.625419 [info ] [MainThread]: 
[0m11:34:34.625896 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:34:34.626947 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 3.6104908, "process_in_blocks": "736", "process_kernel_time": 0.23123, "process_mem_max_rss": "143852", "process_out_blocks": "4088", "process_user_time": 4.823789}
[0m11:34:34.627558 [debug] [MainThread]: Command `dbt run` succeeded at 11:34:34.627400 after 3.61 seconds
[0m11:34:34.628051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a746ac6bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a746c454d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x77a74886edd0>]}
[0m11:34:34.628620 [debug] [MainThread]: Flushing usage events
[0m11:35:57.758269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ceef0e92120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ceeeed9d590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ceeeed9d450>]}


============================== 11:35:57.760965 | 8d04fb53-1610-40b3-856c-aac75fb6c23f ==============================
[0m11:35:57.760965 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:35:57.761464 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar', 'version_check': 'True', 'warn_error': 'None', 'log_path': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/logs', 'fail_fast': 'False', 'debug': 'False', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:35:57.905515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '8d04fb53-1610-40b3-856c-aac75fb6c23f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ceeefdd1cd0>]}
[0m11:35:57.954776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '8d04fb53-1610-40b3-856c-aac75fb6c23f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ceeeec0f790>]}
[0m11:35:57.955449 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:35:58.034205 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:35:58.133414 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m11:35:58.133730 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m11:35:58.138727 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.sakstar.marts
[0m11:35:58.172757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8d04fb53-1610-40b3-856c-aac75fb6c23f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ceeeebe7e50>]}
[0m11:35:58.259794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8d04fb53-1610-40b3-856c-aac75fb6c23f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ceeeebf1f40>]}
[0m11:35:58.260186 [info ] [MainThread]: Found 1 model, 2 data tests, 10 sources, 608 macros
[0m11:35:58.260525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d04fb53-1610-40b3-856c-aac75fb6c23f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ceeee772b30>]}
[0m11:35:58.261950 [info ] [MainThread]: 
[0m11:35:58.262471 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:35:58.263237 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:35:58.275552 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:35:58.476926 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:35:58.479099 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:58.499596 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__adw02_stag)
[0m11:35:58.504426 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw02_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw02_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw02_stag'
      

  ...
[0m11:35:58.518303 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:35:58.519767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8d04fb53-1610-40b3-856c-aac75fb6c23f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ceeec8dd710>]}
[0m11:35:58.520201 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m11:35:58.520498 [info ] [MainThread]: 
[0m11:35:58.522527 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m11:35:58.523015 [info ] [Thread-1 (]: 1 of 1 START sql table model `adw02_stag`.`stg_customer` ....................... [RUN]
[0m11:35:58.523497 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw02_stag, now model.sakstar.stg_customer)
[0m11:35:58.523845 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m11:35:58.530567 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m11:35:58.531125 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m11:35:58.553762 [debug] [Thread-1 (]: Creating new relation stg_customer
[0m11:35:58.583098 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

            

    
        create table `adw02_stag`.`stg_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
          )
        
        ...
[0m11:35:58.604483 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:35:58.619460 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

    select name, type from system.columns where table = 'stg_customer'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:35:58.622939 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:35:58.627066 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m11:35:58.627700 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_customer`
        ("customer_key", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_created", "customer_address", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_last_update", "c.address_id", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
  ...
[0m11:35:58.679693 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m11:35:58.697762 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d04fb53-1610-40b3-856c-aac75fb6c23f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ceeec8ce690>]}
[0m11:35:58.698321 [info ] [Thread-1 (]: 1 of 1 OK created sql table model `adw02_stag`.`stg_customer` .................. [[32mOK[0m in 0.17s]
[0m11:35:58.698857 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m11:35:58.699918 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:35:58.700209 [debug] [MainThread]: Connection 'model.sakstar.stg_customer' was left open.
[0m11:35:58.700531 [debug] [MainThread]: On model.sakstar.stg_customer: Close
[0m11:35:58.700873 [info ] [MainThread]: 
[0m11:35:58.701259 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 0.44 seconds (0.44s).
[0m11:35:58.702045 [debug] [MainThread]: Command end result
[0m11:35:58.729758 [info ] [MainThread]: 
[0m11:35:58.730202 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:35:58.730542 [info ] [MainThread]: 
[0m11:35:58.730903 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m11:35:58.731660 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.01356, "process_in_blocks": "0", "process_kernel_time": 0.136611, "process_mem_max_rss": "138912", "process_out_blocks": "2752", "process_user_time": 1.880829}
[0m11:35:58.732031 [debug] [MainThread]: Command `dbt run` succeeded at 11:35:58.731940 after 1.01 seconds
[0m11:35:58.732373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ceeec8f22b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ceeec4c22b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ceeec4c2210>]}
[0m11:35:58.732690 [debug] [MainThread]: Flushing usage events
[0m11:42:08.707205 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74004a39e120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7400482c1590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7400482c1450>]}


============================== 11:42:08.709952 | a0c8f693-cb89-44fe-a4cf-b3e82bfc879f ==============================
[0m11:42:08.709952 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:42:08.710425 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/logs', 'debug': 'False', 'profiles_dir': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m11:42:08.861436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a0c8f693-cb89-44fe-a4cf-b3e82bfc879f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7400492f5cd0>]}
[0m11:42:08.911538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a0c8f693-cb89-44fe-a4cf-b3e82bfc879f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x740048133790>]}
[0m11:42:08.912090 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:42:08.989954 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:42:09.095178 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 4 files added, 2 files changed.
[0m11:42:09.095664 [debug] [MainThread]: Partial parsing: added file: sakstar://models/staging/staff/stg_staff.sql
[0m11:42:09.095972 [debug] [MainThread]: Partial parsing: added file: sakstar://models/staging/store/stg_store.sql
[0m11:42:09.096432 [debug] [MainThread]: Partial parsing: added file: sakstar://models/staging/store/stg_store.yml
[0m11:42:09.096768 [debug] [MainThread]: Partial parsing: added file: sakstar://models/staging/staff/stg_staff.yml
[0m11:42:09.097154 [debug] [MainThread]: Partial parsing: updated file: sakstar://models/staging/staging_sources.yml
[0m11:42:09.097645 [debug] [MainThread]: Partial parsing: updated file: sakstar://models/staging/customer/stg_customer.sql
[0m11:42:09.303656 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m11:42:09.304057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'a0c8f693-cb89-44fe-a4cf-b3e82bfc879f', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74004810ae50>]}
[0m11:42:09.546941 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.sakstar.marts
[0m11:42:09.557894 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a0c8f693-cb89-44fe-a4cf-b3e82bfc879f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x740047dbe300>]}
[0m11:42:09.693811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a0c8f693-cb89-44fe-a4cf-b3e82bfc879f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x740047c335b0>]}
[0m11:42:09.694229 [info ] [MainThread]: Found 3 models, 6 data tests, 10 sources, 608 macros
[0m11:42:09.694629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a0c8f693-cb89-44fe-a4cf-b3e82bfc879f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x740047b635f0>]}
[0m11:42:09.696635 [info ] [MainThread]: 
[0m11:42:09.697113 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:42:09.703103 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:42:09.712519 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:42:09.902741 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:42:09.905496 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:42:09.926724 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__adw02_stag)
[0m11:42:09.931507 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw02_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw02_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw02_stag'
      

  ...
[0m11:42:09.943183 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:42:09.944664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a0c8f693-cb89-44fe-a4cf-b3e82bfc879f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7400464b2450>]}
[0m11:42:09.945115 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m11:42:09.945427 [info ] [MainThread]: 
[0m11:42:09.947459 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m11:42:09.948103 [info ] [Thread-1 (]: 1 of 3 START sql table model `adw02_stag`.`stg_customer` ....................... [RUN]
[0m11:42:09.948794 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw02_stag, now model.sakstar.stg_customer)
[0m11:42:09.949144 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m11:42:09.955401 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m11:42:09.955944 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m11:42:09.973455 [debug] [Thread-1 (]: Creating new relation stg_customer
[0m11:42:10.005095 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

            

    
        create table `adw02_stag`.`stg_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila.address a ON c.address_id = a.address_id
    JOIN sakila.city ci ON a.city_id = ci.city_id
    JOIN sakila.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
          )
        
        ...
[0m11:42:10.013882 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

            

    
        create table `adw02_stag`.`stg_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila.address a ON c.address_id = a.address_id
    JOIN sakila.city ci ON a.city_id = ci.city_id
    JOIN sakila.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
          )
        
        
[0m11:42:10.023103 [debug] [Thread-1 (]: Database Error in model stg_customer (models/staging/customer/stg_customer.sql)
  Code: 81.
  DB::Exception: Database sakila does not exist. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000000f2be35b
  1. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x0000000009c73bec
  2. DB::Exception::Exception<String>(int, FormatStringHelperImpl<std::type_identity<String>::type>, String&&) @ 0x0000000009c7390b
  3. DB::DatabaseCatalog::getDatabase(String const&) const @ 0x00000000130c872a
  4. DB::Context::resolveStorageID(DB::StorageID, DB::Context::StorageNamespace) const @ 0x0000000012ffb35e
  5. DB::IdentifierResolver::tryResolveTableIdentifier(DB::Identifier const&, std::shared_ptr<DB::Context const> const&) @ 0x0000000012b27058
  6. DB::QueryAnalyzer::tryResolveIdentifier(DB::IdentifierLookup const&, DB::IdentifierResolveScope&, DB::IdentifierResolveContext) @ 0x00000000128ed633
  7. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x00000000128d0ebf
  8. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000128dbc5c
  9. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001290c523
  10. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x00000000128d186f
  11. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x00000000128cfb8c
  12. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x00000000128cf3f3
  13. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x0000000012924db6
  14. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.5923817706791937394) @ 0x0000000013234fe5
  15. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x0000000013232f7c
  16. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x0000000013235419
  17. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000131981de
  18. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000131a0c2a
  19. DB::InterpreterCreateQuery::execute() @ 0x00000000131b6678
  20. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*, std::shared_ptr<DB::IAST>&) @ 0x00000000135904e8
  21. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x0000000013589be6
  22. DB::TCPHandler::runImpl() @ 0x00000000148e9cfe
  23. DB::TCPHandler::run() @ 0x00000000149089f9
  24. Poco::Net::TCPServerConnection::start() @ 0x000000001800e967
  25. Poco::Net::TCPServerDispatcher::run() @ 0x000000001800edb9
  26. Poco::PooledThread::run() @ 0x0000000017fda0db
  27. Poco::ThreadImpl::runnableEntry(void*) @ 0x0000000017fd85bd
  28. ? @ 0x00007fb490894ac3
  29. ? @ 0x00007fb490926850
[0m11:42:10.024478 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0c8f693-cb89-44fe-a4cf-b3e82bfc879f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x740044190050>]}
[0m11:42:10.025020 [error] [Thread-1 (]: 1 of 3 ERROR creating sql table model `adw02_stag`.`stg_customer` .............. [[31mERROR[0m in 0.07s]
[0m11:42:10.025837 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m11:42:10.026263 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m11:42:10.026715 [info ] [Thread-1 (]: 2 of 3 START sql table model `adw02_stag`.`stg_staff` .......................... [RUN]
[0m11:42:10.027128 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_staff)
[0m11:42:10.027458 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m11:42:10.029106 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m11:42:10.030333 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m11:42:10.032779 [debug] [Thread-1 (]: Creating new relation stg_staff
[0m11:42:10.033821 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

            

    
        create table `adw02_stag`.`stg_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
          )
        
        ...
[0m11:42:10.038317 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

            

    
        create table `adw02_stag`.`stg_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
          )
        
        
[0m11:42:10.046357 [debug] [Thread-1 (]: Database Error in model stg_staff (models/staging/staff/stg_staff.sql)
  Code: 81.
  DB::Exception: Database sakila does not exist. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000000f2be35b
  1. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x0000000009c73bec
  2. DB::Exception::Exception<String>(int, FormatStringHelperImpl<std::type_identity<String>::type>, String&&) @ 0x0000000009c7390b
  3. DB::DatabaseCatalog::getDatabase(String const&) const @ 0x00000000130c872a
  4. DB::Context::resolveStorageID(DB::StorageID, DB::Context::StorageNamespace) const @ 0x0000000012ffb35e
  5. DB::IdentifierResolver::tryResolveTableIdentifier(DB::Identifier const&, std::shared_ptr<DB::Context const> const&) @ 0x0000000012b27058
  6. DB::QueryAnalyzer::tryResolveIdentifier(DB::IdentifierLookup const&, DB::IdentifierResolveScope&, DB::IdentifierResolveContext) @ 0x00000000128ed633
  7. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x00000000128d0ebf
  8. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000128dbc5c
  9. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001290c523
  10. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x00000000128d186f
  11. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x00000000128cfb8c
  12. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x00000000128cf3f3
  13. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x0000000012924db6
  14. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.5923817706791937394) @ 0x0000000013234fe5
  15. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x0000000013232f7c
  16. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x0000000013235419
  17. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000131981de
  18. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000131a0c2a
  19. DB::InterpreterCreateQuery::execute() @ 0x00000000131b6678
  20. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*, std::shared_ptr<DB::IAST>&) @ 0x00000000135904e8
  21. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x0000000013589be6
  22. DB::TCPHandler::runImpl() @ 0x00000000148e9cfe
  23. DB::TCPHandler::run() @ 0x00000000149089f9
  24. Poco::Net::TCPServerConnection::start() @ 0x000000001800e967
  25. Poco::Net::TCPServerDispatcher::run() @ 0x000000001800edb9
  26. Poco::PooledThread::run() @ 0x0000000017fda0db
  27. Poco::ThreadImpl::runnableEntry(void*) @ 0x0000000017fd85bd
  28. ? @ 0x00007fb490894ac3
  29. ? @ 0x00007fb490926850
[0m11:42:10.046935 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0c8f693-cb89-44fe-a4cf-b3e82bfc879f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7400443379d0>]}
[0m11:42:10.047576 [error] [Thread-1 (]: 2 of 3 ERROR creating sql table model `adw02_stag`.`stg_staff` ................. [[31mERROR[0m in 0.02s]
[0m11:42:10.048205 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m11:42:10.048596 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m11:42:10.049000 [info ] [Thread-1 (]: 3 of 3 START sql table model `adw02_stag`.`stg_store` .......................... [RUN]
[0m11:42:10.049705 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_store)
[0m11:42:10.050189 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m11:42:10.051965 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m11:42:10.052590 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m11:42:10.054768 [debug] [Thread-1 (]: Creating new relation stg_store
[0m11:42:10.055679 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

            

    
        create table `adw02_stag`.`stg_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila.address a ON s.address_id = a.address_id
    JOIN sakila.city ci ON a.city_id = ci.city_id
    JOIN sakila.country co ON ci.country_id = co.country_id
    JOIN sakila.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
          )
        
        ...
[0m11:42:10.060534 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

            

    
        create table `adw02_stag`.`stg_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila.address a ON s.address_id = a.address_id
    JOIN sakila.city ci ON a.city_id = ci.city_id
    JOIN sakila.country co ON ci.country_id = co.country_id
    JOIN sakila.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
          )
        
        
[0m11:42:10.068160 [debug] [Thread-1 (]: Database Error in model stg_store (models/staging/store/stg_store.sql)
  Code: 81.
  DB::Exception: Database sakila does not exist. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000000f2be35b
  1. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x0000000009c73bec
  2. DB::Exception::Exception<String>(int, FormatStringHelperImpl<std::type_identity<String>::type>, String&&) @ 0x0000000009c7390b
  3. DB::DatabaseCatalog::getDatabase(String const&) const @ 0x00000000130c872a
  4. DB::Context::resolveStorageID(DB::StorageID, DB::Context::StorageNamespace) const @ 0x0000000012ffb35e
  5. DB::IdentifierResolver::tryResolveTableIdentifier(DB::Identifier const&, std::shared_ptr<DB::Context const> const&) @ 0x0000000012b27058
  6. DB::QueryAnalyzer::tryResolveIdentifier(DB::IdentifierLookup const&, DB::IdentifierResolveScope&, DB::IdentifierResolveContext) @ 0x00000000128ed633
  7. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x00000000128d0ebf
  8. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000128dbc5c
  9. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001290c523
  10. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x00000000128d186f
  11. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x00000000128cfb8c
  12. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x00000000128cf3f3
  13. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x0000000012924db6
  14. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.5923817706791937394) @ 0x0000000013234fe5
  15. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x0000000013232f7c
  16. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x0000000013235419
  17. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000131981de
  18. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000131a0c2a
  19. DB::InterpreterCreateQuery::execute() @ 0x00000000131b6678
  20. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*, std::shared_ptr<DB::IAST>&) @ 0x00000000135904e8
  21. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x0000000013589be6
  22. DB::TCPHandler::runImpl() @ 0x00000000148e9cfe
  23. DB::TCPHandler::run() @ 0x00000000149089f9
  24. Poco::Net::TCPServerConnection::start() @ 0x000000001800e967
  25. Poco::Net::TCPServerDispatcher::run() @ 0x000000001800edb9
  26. Poco::PooledThread::run() @ 0x0000000017fda0db
  27. Poco::ThreadImpl::runnableEntry(void*) @ 0x0000000017fd85bd
  28. ? @ 0x00007fb490894ac3
  29. ? @ 0x00007fb490926850
[0m11:42:10.068716 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0c8f693-cb89-44fe-a4cf-b3e82bfc879f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7400441906d0>]}
[0m11:42:10.069226 [error] [Thread-1 (]: 3 of 3 ERROR creating sql table model `adw02_stag`.`stg_store` ................. [[31mERROR[0m in 0.02s]
[0m11:42:10.069914 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m11:42:10.071261 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:42:10.071675 [debug] [MainThread]: Connection 'model.sakstar.stg_store' was left open.
[0m11:42:10.072006 [debug] [MainThread]: On model.sakstar.stg_store: Close
[0m11:42:10.072376 [info ] [MainThread]: 
[0m11:42:10.072714 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.38 seconds (0.38s).
[0m11:42:10.074110 [debug] [MainThread]: Command end result
[0m11:42:10.106624 [info ] [MainThread]: 
[0m11:42:10.107003 [info ] [MainThread]: [31mCompleted with 3 errors and 0 warnings:[0m
[0m11:42:10.107284 [info ] [MainThread]: 
[0m11:42:10.107823 [error] [MainThread]:   Database Error in model stg_customer (models/staging/customer/stg_customer.sql)
  Code: 81.
  DB::Exception: Database sakila does not exist. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000000f2be35b
  1. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x0000000009c73bec
  2. DB::Exception::Exception<String>(int, FormatStringHelperImpl<std::type_identity<String>::type>, String&&) @ 0x0000000009c7390b
  3. DB::DatabaseCatalog::getDatabase(String const&) const @ 0x00000000130c872a
  4. DB::Context::resolveStorageID(DB::StorageID, DB::Context::StorageNamespace) const @ 0x0000000012ffb35e
  5. DB::IdentifierResolver::tryResolveTableIdentifier(DB::Identifier const&, std::shared_ptr<DB::Context const> const&) @ 0x0000000012b27058
  6. DB::QueryAnalyzer::tryResolveIdentifier(DB::IdentifierLookup const&, DB::IdentifierResolveScope&, DB::IdentifierResolveContext) @ 0x00000000128ed633
  7. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x00000000128d0ebf
  8. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000128dbc5c
  9. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001290c523
  10. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x00000000128d186f
  11. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x00000000128cfb8c
  12. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x00000000128cf3f3
  13. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x0000000012924db6
  14. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.5923817706791937394) @ 0x0000000013234fe5
  15. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x0000000013232f7c
  16. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x0000000013235419
  17. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000131981de
  18. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000131a0c2a
  19. DB::InterpreterCreateQuery::execute() @ 0x00000000131b6678
  20. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*, std::shared_ptr<DB::IAST>&) @ 0x00000000135904e8
  21. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x0000000013589be6
  22. DB::TCPHandler::runImpl() @ 0x00000000148e9cfe
  23. DB::TCPHandler::run() @ 0x00000000149089f9
  24. Poco::Net::TCPServerConnection::start() @ 0x000000001800e967
  25. Poco::Net::TCPServerDispatcher::run() @ 0x000000001800edb9
  26. Poco::PooledThread::run() @ 0x0000000017fda0db
  27. Poco::ThreadImpl::runnableEntry(void*) @ 0x0000000017fd85bd
  28. ? @ 0x00007fb490894ac3
  29. ? @ 0x00007fb490926850
[0m11:42:10.108255 [info ] [MainThread]: 
[0m11:42:10.108800 [error] [MainThread]:   Database Error in model stg_staff (models/staging/staff/stg_staff.sql)
  Code: 81.
  DB::Exception: Database sakila does not exist. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000000f2be35b
  1. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x0000000009c73bec
  2. DB::Exception::Exception<String>(int, FormatStringHelperImpl<std::type_identity<String>::type>, String&&) @ 0x0000000009c7390b
  3. DB::DatabaseCatalog::getDatabase(String const&) const @ 0x00000000130c872a
  4. DB::Context::resolveStorageID(DB::StorageID, DB::Context::StorageNamespace) const @ 0x0000000012ffb35e
  5. DB::IdentifierResolver::tryResolveTableIdentifier(DB::Identifier const&, std::shared_ptr<DB::Context const> const&) @ 0x0000000012b27058
  6. DB::QueryAnalyzer::tryResolveIdentifier(DB::IdentifierLookup const&, DB::IdentifierResolveScope&, DB::IdentifierResolveContext) @ 0x00000000128ed633
  7. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x00000000128d0ebf
  8. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000128dbc5c
  9. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001290c523
  10. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x00000000128d186f
  11. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x00000000128cfb8c
  12. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x00000000128cf3f3
  13. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x0000000012924db6
  14. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.5923817706791937394) @ 0x0000000013234fe5
  15. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x0000000013232f7c
  16. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x0000000013235419
  17. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000131981de
  18. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000131a0c2a
  19. DB::InterpreterCreateQuery::execute() @ 0x00000000131b6678
  20. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*, std::shared_ptr<DB::IAST>&) @ 0x00000000135904e8
  21. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x0000000013589be6
  22. DB::TCPHandler::runImpl() @ 0x00000000148e9cfe
  23. DB::TCPHandler::run() @ 0x00000000149089f9
  24. Poco::Net::TCPServerConnection::start() @ 0x000000001800e967
  25. Poco::Net::TCPServerDispatcher::run() @ 0x000000001800edb9
  26. Poco::PooledThread::run() @ 0x0000000017fda0db
  27. Poco::ThreadImpl::runnableEntry(void*) @ 0x0000000017fd85bd
  28. ? @ 0x00007fb490894ac3
  29. ? @ 0x00007fb490926850
[0m11:42:10.109376 [info ] [MainThread]: 
[0m11:42:10.109896 [error] [MainThread]:   Database Error in model stg_store (models/staging/store/stg_store.sql)
  Code: 81.
  DB::Exception: Database sakila does not exist. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000000f2be35b
  1. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x0000000009c73bec
  2. DB::Exception::Exception<String>(int, FormatStringHelperImpl<std::type_identity<String>::type>, String&&) @ 0x0000000009c7390b
  3. DB::DatabaseCatalog::getDatabase(String const&) const @ 0x00000000130c872a
  4. DB::Context::resolveStorageID(DB::StorageID, DB::Context::StorageNamespace) const @ 0x0000000012ffb35e
  5. DB::IdentifierResolver::tryResolveTableIdentifier(DB::Identifier const&, std::shared_ptr<DB::Context const> const&) @ 0x0000000012b27058
  6. DB::QueryAnalyzer::tryResolveIdentifier(DB::IdentifierLookup const&, DB::IdentifierResolveScope&, DB::IdentifierResolveContext) @ 0x00000000128ed633
  7. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x00000000128d0ebf
  8. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000128dbc5c
  9. DB::QueryAnalyzer::resolveQueryJoinTreeNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, DB::QueryExpressionsAliasVisitor&) @ 0x000000001290c523
  10. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x00000000128d186f
  11. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x00000000128cfb8c
  12. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x00000000128cf3f3
  13. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x0000000012924db6
  14. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.5923817706791937394) @ 0x0000000013234fe5
  15. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x0000000013232f7c
  16. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x0000000013235419
  17. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000131981de
  18. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000131a0c2a
  19. DB::InterpreterCreateQuery::execute() @ 0x00000000131b6678
  20. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*, std::shared_ptr<DB::IAST>&) @ 0x00000000135904e8
  21. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x0000000013589be6
  22. DB::TCPHandler::runImpl() @ 0x00000000148e9cfe
  23. DB::TCPHandler::run() @ 0x00000000149089f9
  24. Poco::Net::TCPServerConnection::start() @ 0x000000001800e967
  25. Poco::Net::TCPServerDispatcher::run() @ 0x000000001800edb9
  26. Poco::PooledThread::run() @ 0x0000000017fda0db
  27. Poco::ThreadImpl::runnableEntry(void*) @ 0x0000000017fd85bd
  28. ? @ 0x00007fb490894ac3
  29. ? @ 0x00007fb490926850
[0m11:42:10.110332 [info ] [MainThread]: 
[0m11:42:10.110723 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=3 SKIP=0 TOTAL=3
[0m11:42:10.111539 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.4441557, "process_in_blocks": "0", "process_kernel_time": 0.137155, "process_mem_max_rss": "143576", "process_out_blocks": "4288", "process_user_time": 2.376092}
[0m11:42:10.111942 [debug] [MainThread]: Command `dbt run` failed at 11:42:10.111850 after 1.44 seconds
[0m11:42:10.112272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x740048182dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74004c2788a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74004a0df710>]}
[0m11:42:10.112633 [debug] [MainThread]: Flushing usage events
[0m11:43:09.002791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7235c559a120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7235c34a5590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7235c34a5450>]}


============================== 11:43:09.005477 | 40700d89-6305-489e-be3c-3f35d857d38c ==============================
[0m11:43:09.005477 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:43:09.005941 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'invocation_command': 'dbt run', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:43:09.155459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '40700d89-6305-489e-be3c-3f35d857d38c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7235c44d9cd0>]}
[0m11:43:09.206458 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '40700d89-6305-489e-be3c-3f35d857d38c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7235c3317790>]}
[0m11:43:09.207212 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:43:09.290255 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:43:09.395141 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 4 files changed.
[0m11:43:09.395687 [debug] [MainThread]: Partial parsing: updated file: sakstar://models/staging/staging_sources.yml
[0m11:43:09.396083 [debug] [MainThread]: Partial parsing: updated file: sakstar://models/staging/staff/stg_staff.sql
[0m11:43:09.396570 [debug] [MainThread]: Partial parsing: updated file: sakstar://models/staging/customer/stg_customer.sql
[0m11:43:09.396932 [debug] [MainThread]: Partial parsing: updated file: sakstar://models/staging/store/stg_store.sql
[0m11:43:09.656143 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m11:43:09.656553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '40700d89-6305-489e-be3c-3f35d857d38c', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7235c2f24250>]}
[0m11:43:09.829392 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.sakstar.marts
[0m11:43:09.839057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '40700d89-6305-489e-be3c-3f35d857d38c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7235c1483b60>]}
[0m11:43:09.970550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '40700d89-6305-489e-be3c-3f35d857d38c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7235c152e5f0>]}
[0m11:43:09.970992 [info ] [MainThread]: Found 3 models, 6 data tests, 10 sources, 608 macros
[0m11:43:09.971316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '40700d89-6305-489e-be3c-3f35d857d38c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7235c2f5b5f0>]}
[0m11:43:09.973002 [info ] [MainThread]: 
[0m11:43:09.973506 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:43:09.979038 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:43:09.988811 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:43:10.200596 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:43:10.208826 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:43:10.254479 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__adw02_stag)
[0m11:43:10.259605 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw02_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw02_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw02_stag'
      

  ...
[0m11:43:10.273465 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:43:10.275008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '40700d89-6305-489e-be3c-3f35d857d38c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7235c14965d0>]}
[0m11:43:10.275661 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m11:43:10.276172 [info ] [MainThread]: 
[0m11:43:10.278439 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m11:43:10.278964 [info ] [Thread-1 (]: 1 of 3 START sql table model `adw02_stag`.`stg_customer` ....................... [RUN]
[0m11:43:10.279467 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw02_stag, now model.sakstar.stg_customer)
[0m11:43:10.279887 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m11:43:10.286526 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m11:43:10.287199 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m11:43:10.305669 [debug] [Thread-1 (]: Creating new relation stg_customer
[0m11:43:10.336924 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

            

    
        create table `adw02_stag`.`stg_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
          )
        
        ...
[0m11:43:10.352588 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:43:10.368283 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

    select name, type from system.columns where table = 'stg_customer'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:43:10.372183 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:43:10.376629 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m11:43:10.377244 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_customer`
        ("customer_key", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_created", "customer_address", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_last_update", "c.address_id", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
  ...
[0m11:43:10.429743 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m11:43:10.449758 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '40700d89-6305-489e-be3c-3f35d857d38c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7235b32cc310>]}
[0m11:43:10.450443 [info ] [Thread-1 (]: 1 of 3 OK created sql table model `adw02_stag`.`stg_customer` .................. [[32mOK[0m in 0.17s]
[0m11:43:10.451155 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m11:43:10.451782 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m11:43:10.452332 [info ] [Thread-1 (]: 2 of 3 START sql table model `adw02_stag`.`stg_staff` .......................... [RUN]
[0m11:43:10.452801 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_staff)
[0m11:43:10.453200 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m11:43:10.455015 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m11:43:10.455848 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m11:43:10.458206 [debug] [Thread-1 (]: Creating new relation stg_staff
[0m11:43:10.459671 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

            

    
        create table `adw02_stag`.`stg_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
          )
        
        ...
[0m11:43:10.471589 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:43:10.474536 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

    select name, type from system.columns where table = 'stg_staff'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:43:10.477822 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:43:10.480010 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff"
[0m11:43:10.480681 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_staff`
        ("staff_key", "staff_first_name", "staff_last_name", "staff_email", "staff_active", "staff_username", "staff_password", "staff_last_update", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
  ...
[0m11:43:10.495602 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:43:10.497553 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '40700d89-6305-489e-be3c-3f35d857d38c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7235b327f7f0>]}
[0m11:43:10.498062 [info ] [Thread-1 (]: 2 of 3 OK created sql table model `adw02_stag`.`stg_staff` ..................... [[32mOK[0m in 0.04s]
[0m11:43:10.498649 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m11:43:10.499010 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m11:43:10.499560 [info ] [Thread-1 (]: 3 of 3 START sql table model `adw02_stag`.`stg_store` .......................... [RUN]
[0m11:43:10.500148 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_store)
[0m11:43:10.500562 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m11:43:10.506677 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m11:43:10.507204 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m11:43:10.508965 [debug] [Thread-1 (]: Creating new relation stg_store
[0m11:43:10.509988 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

            

    
        create table `adw02_stag`.`stg_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila_proxy.address a ON s.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
    JOIN sakila_proxy.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
          )
        
        ...
[0m11:43:10.527704 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:43:10.530300 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

    select name, type from system.columns where table = 'stg_store'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:43:10.533517 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:43:10.535664 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store"
[0m11:43:10.536214 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_store`
        ("store_key", "store_address", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")WITH source AS (
    SELECT * FROM sakila_proxy.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila_proxy.address a ON s.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
    JOIN sakila_proxy.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
  ...
[0m11:43:10.596417 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m11:43:10.597973 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '40700d89-6305-489e-be3c-3f35d857d38c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7235c2df9350>]}
[0m11:43:10.598480 [info ] [Thread-1 (]: 3 of 3 OK created sql table model `adw02_stag`.`stg_store` ..................... [[32mOK[0m in 0.10s]
[0m11:43:10.598992 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m11:43:10.600193 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:43:10.600483 [debug] [MainThread]: Connection 'model.sakstar.stg_store' was left open.
[0m11:43:10.600759 [debug] [MainThread]: On model.sakstar.stg_store: Close
[0m11:43:10.601143 [info ] [MainThread]: 
[0m11:43:10.601603 [info ] [MainThread]: Finished running 3 table models in 0 hours 0 minutes and 0.63 seconds (0.63s).
[0m11:43:10.602648 [debug] [MainThread]: Command end result
[0m11:43:10.631449 [info ] [MainThread]: 
[0m11:43:10.631833 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:43:10.632119 [info ] [MainThread]: 
[0m11:43:10.632421 [info ] [MainThread]: Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
[0m11:43:10.633087 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.6717633, "process_in_blocks": "0", "process_kernel_time": 0.162057, "process_mem_max_rss": "143156", "process_out_blocks": "4264", "process_user_time": 2.340379}
[0m11:43:10.633462 [debug] [MainThread]: Command `dbt run` succeeded at 11:43:10.633369 after 1.67 seconds
[0m11:43:10.633781 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7235c3366dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7235c75388a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7235c48abb90>]}
[0m11:43:10.634101 [debug] [MainThread]: Flushing usage events
[0m11:46:06.683579 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78b348e120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78b13ad590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78b13ad450>]}


============================== 11:46:06.686360 | 6b6f7a99-c9e8-4e92-99bf-b2c46333044f ==============================
[0m11:46:06.686360 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:46:06.686898 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'profiles_dir': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar', 'log_path': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/logs', 'debug': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'introspect': 'True', 'static_parser': 'True', 'target_path': 'None', 'log_format': 'default', 'send_anonymous_usage_stats': 'True'}
[0m11:46:06.832898 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '6b6f7a99-c9e8-4e92-99bf-b2c46333044f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78b23e1cd0>]}
[0m11:46:06.884443 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '6b6f7a99-c9e8-4e92-99bf-b2c46333044f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78b121f790>]}
[0m11:46:06.885108 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:46:06.968518 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:46:07.072738 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 4 files added, 0 files changed.
[0m11:46:07.073365 [debug] [MainThread]: Partial parsing: added file: sakstar://models/staging/rental/stg_rental.yml
[0m11:46:07.073719 [debug] [MainThread]: Partial parsing: added file: sakstar://models/staging/rental/stg_rental.sql
[0m11:46:07.074010 [debug] [MainThread]: Partial parsing: added file: sakstar://models/staging/film/stg_film.sql
[0m11:46:07.074447 [debug] [MainThread]: Partial parsing: added file: sakstar://models/staging/film/stg_film.yml
[0m11:46:07.276216 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m11:46:07.276662 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '6b6f7a99-c9e8-4e92-99bf-b2c46333044f', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78b0e31550>]}
[0m11:46:07.427693 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.sakstar.marts
[0m11:46:07.439891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6b6f7a99-c9e8-4e92-99bf-b2c46333044f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78b0f48e60>]}
[0m11:46:07.539401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6b6f7a99-c9e8-4e92-99bf-b2c46333044f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78b00cc9f0>]}
[0m11:46:07.539804 [info ] [MainThread]: Found 5 models, 10 data tests, 10 sources, 608 macros
[0m11:46:07.540186 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6b6f7a99-c9e8-4e92-99bf-b2c46333044f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78b00ffa00>]}
[0m11:46:07.542617 [info ] [MainThread]: 
[0m11:46:07.543134 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:46:07.549624 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:46:07.561086 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:46:07.824186 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:46:07.833300 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:46:07.882016 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__adw02_stag)
[0m11:46:07.887255 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw02_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw02_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw02_stag'
      

  ...
[0m11:46:07.899318 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:46:07.901247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6b6f7a99-c9e8-4e92-99bf-b2c46333044f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78ab112150>]}
[0m11:46:07.901821 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m11:46:07.902142 [info ] [MainThread]: 
[0m11:46:07.904565 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m11:46:07.905070 [info ] [Thread-1 (]: 1 of 5 START sql table model `adw02_stag`.`stg_customer` ....................... [RUN]
[0m11:46:07.905586 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw02_stag, now model.sakstar.stg_customer)
[0m11:46:07.905902 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m11:46:07.912247 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m11:46:07.912859 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m11:46:07.930569 [debug] [Thread-1 (]: Creating new relation stg_customer
[0m11:46:07.960736 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

            

    
        create table `adw02_stag`.`stg_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
          )
        
        ...
[0m11:46:07.976459 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:46:07.991132 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

    select name, type from system.columns where table = 'stg_customer'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:46:07.994842 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:46:07.999168 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m11:46:07.999784 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_customer`
        ("customer_key", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_created", "customer_address", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_last_update", "c.address_id", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
  ...
[0m11:46:08.052409 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m11:46:08.070499 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b6f7a99-c9e8-4e92-99bf-b2c46333044f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78a943fb70>]}
[0m11:46:08.071031 [info ] [Thread-1 (]: 1 of 5 OK created sql table model `adw02_stag`.`stg_customer` .................. [[32mOK[0m in 0.16s]
[0m11:46:08.071703 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m11:46:08.072080 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film
[0m11:46:08.072658 [info ] [Thread-1 (]: 2 of 5 START sql table model `adw02_stag`.`stg_film` ........................... [RUN]
[0m11:46:08.073178 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_film)
[0m11:46:08.073651 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film
[0m11:46:08.075304 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_film"
[0m11:46:08.075909 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_film
[0m11:46:08.078267 [debug] [Thread-1 (]: Creating new relation stg_film
[0m11:46:08.079563 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

            

    
        create table `adw02_stag`.`stg_film`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.film
)
SELECT
    f.film_id as film_key,
    f.title as film_title,
    f.description as film_description,
    f.release_year as film_release_year,
    l.name as film_language,
    CASE WHEN f.original_language_id IS NOT NULL THEN 1 ELSE 0 END as film_has_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.length as film_duration,
    f.replacement_cost as film_replacement_cost,
    f.rating as film_rating,
    f.special_features as film_special_features,
    f.last_update as film_last_update
FROM source f
JOIN sakila_proxy.language l ON f.language_id = l.language_id
          )
        
        ...
[0m11:46:08.102016 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:46:08.112609 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

    select name, type from system.columns where table = 'stg_film'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:46:08.125950 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:46:08.135200 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_film"
[0m11:46:08.137031 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_film`
        ("film_key", "film_title", "film_description", "film_release_year", "film_language", "film_has_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_last_update")WITH source AS (
    SELECT * FROM sakila_proxy.film
)
SELECT
    f.film_id as film_key,
    f.title as film_title,
    f.description as film_description,
    f.release_year as film_release_year,
    l.name as film_language,
    CASE WHEN f.original_language_id IS NOT NULL THEN 1 ELSE 0 END as film_has_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.length as film_duration,
    f.replacement_cost as film_replacement_cost,
    f.rating as film_rating,
    f.special_features as film_special_features,
    f.last_update as film_last_update
FROM source f
JOIN sakila_proxy.language l ON f.language_id = l.language_id
  ...
[0m11:46:08.191881 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m11:46:08.194835 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b6f7a99-c9e8-4e92-99bf-b2c46333044f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78a91bba70>]}
[0m11:46:08.195850 [info ] [Thread-1 (]: 2 of 5 OK created sql table model `adw02_stag`.`stg_film` ...................... [[32mOK[0m in 0.12s]
[0m11:46:08.196984 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film
[0m11:46:08.197891 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rental
[0m11:46:08.198799 [info ] [Thread-1 (]: 3 of 5 START sql table model `adw02_stag`.`stg_rental` ......................... [RUN]
[0m11:46:08.199779 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film, now model.sakstar.stg_rental)
[0m11:46:08.200672 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rental
[0m11:46:08.204396 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_rental"
[0m11:46:08.205472 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_rental
[0m11:46:08.208949 [debug] [Thread-1 (]: Creating new relation stg_rental
[0m11:46:08.210931 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

            

    
        create table `adw02_stag`.`stg_rental`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.rental
),
inventory AS (
    SELECT * FROM sakila_proxy.inventory
)
SELECT
    r.rental_id as rental_key,
    r.customer_id as customer_key,
    i.film_id as film_key,
    r.staff_id as staff_key,
    i.store_id as store_key,
    r.rental_date,
    r.return_date,
    i.inventory_id,
    DATEDIFF(r.return_date, r.rental_date) as rental_duration,
    r.last_update
FROM source r
JOIN inventory i ON r.inventory_id = i.inventory_id
          )
        
        ...
[0m11:46:08.231564 [debug] [Thread-1 (]: dbt_clickhouse adapter: Error running SQL: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

            

    
        create table `adw02_stag`.`stg_rental`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.rental
),
inventory AS (
    SELECT * FROM sakila_proxy.inventory
)
SELECT
    r.rental_id as rental_key,
    r.customer_id as customer_key,
    i.film_id as film_key,
    r.staff_id as staff_key,
    i.store_id as store_key,
    r.rental_date,
    r.return_date,
    i.inventory_id,
    DATEDIFF(r.return_date, r.rental_date) as rental_duration,
    r.last_update
FROM source r
JOIN inventory i ON r.inventory_id = i.inventory_id
          )
        
        
[0m11:46:08.248920 [debug] [Thread-1 (]: Database Error in model stg_rental (models/staging/rental/stg_rental.sql)
  Code: 42.
  DB::Exception: An incorrect number of arguments was specified for function 'dateDiff'. Expected 3 mandatory arguments and 1 optional argument, got 2 arguments: In scope WITH source AS (SELECT * FROM sakila_proxy.rental), inventory AS (SELECT * FROM sakila_proxy.inventory) SELECT r.rental_id AS rental_key, r.customer_id AS customer_key, i.film_id AS film_key, r.staff_id AS staff_key, i.store_id AS store_key, r.rental_date, r.return_date, i.inventory_id, dateDiff(r.return_date, r.rental_date) AS rental_duration, r.last_update FROM source AS r INNER JOIN inventory AS i ON r.inventory_id = i.inventory_id. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000000f2be35b
  1. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x0000000009c73bec
  2. DB::Exception::Exception<String, String&, String>(int, FormatStringHelperImpl<std::type_identity<String>::type, std::type_identity<String&>::type, std::type_identity<String>::type>, String&&, String&, String&&) @ 0x0000000011997beb
  3. DB::validateFunctionArguments(DB::IFunction const&, std::vector<DB::ColumnWithTypeAndName, std::allocator<DB::ColumnWithTypeAndName>> const&, std::vector<DB::FunctionArgumentDescriptor, std::allocator<DB::FunctionArgumentDescriptor>> const&, std::vector<DB::FunctionArgumentDescriptor, std::allocator<DB::FunctionArgumentDescriptor>> const&) @ 0x0000000011997abf
  4. DB::(anonymous namespace)::FunctionDateDiff<true>::getReturnTypeImpl(std::vector<DB::ColumnWithTypeAndName, std::allocator<DB::ColumnWithTypeAndName>> const&) const @ 0x000000000ad638b3
  5. DB::IFunctionOverloadResolver::getReturnTypeWithoutLowCardinality(std::vector<DB::ColumnWithTypeAndName, std::allocator<DB::ColumnWithTypeAndName>> const&) const @ 0x0000000011987310
  6. DB::IFunctionOverloadResolver::build(std::vector<DB::ColumnWithTypeAndName, std::allocator<DB::ColumnWithTypeAndName>> const&) const @ 0x0000000011987daa
  7. DB::QueryAnalyzer::resolveFunction(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x00000000128f773e
  8. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000128dbd20
  9. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000128db154
  10. DB::QueryAnalyzer::resolveProjectionExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x000000001290bba7
  11. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x00000000128d18ba
  12. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x00000000128cfb8c
  13. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x00000000128cf3f3
  14. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x0000000012924db6
  15. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.5923817706791937394) @ 0x0000000013234fe5
  16. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x0000000013232f7c
  17. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x0000000013235419
  18. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000131981de
  19. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000131a0c2a
  20. DB::InterpreterCreateQuery::execute() @ 0x00000000131b6678
  21. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*, std::shared_ptr<DB::IAST>&) @ 0x00000000135904e8
  22. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x0000000013589be6
  23. DB::TCPHandler::runImpl() @ 0x00000000148e9cfe
  24. DB::TCPHandler::run() @ 0x00000000149089f9
  25. Poco::Net::TCPServerConnection::start() @ 0x000000001800e967
  26. Poco::Net::TCPServerDispatcher::run() @ 0x000000001800edb9
  27. Poco::PooledThread::run() @ 0x0000000017fda0db
  28. Poco::ThreadImpl::runnableEntry(void*) @ 0x0000000017fd85bd
  29. ? @ 0x00007fb490894ac3
  30. ? @ 0x00007fb490926850
[0m11:46:08.249985 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b6f7a99-c9e8-4e92-99bf-b2c46333044f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78a92b8dd0>]}
[0m11:46:08.251026 [error] [Thread-1 (]: 3 of 5 ERROR creating sql table model `adw02_stag`.`stg_rental` ................ [[31mERROR[0m in 0.05s]
[0m11:46:08.252671 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rental
[0m11:46:08.253318 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m11:46:08.254106 [info ] [Thread-1 (]: 4 of 5 START sql table model `adw02_stag`.`stg_staff` .......................... [RUN]
[0m11:46:08.254896 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rental, now model.sakstar.stg_staff)
[0m11:46:08.255736 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m11:46:08.258636 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m11:46:08.260103 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m11:46:08.262497 [debug] [Thread-1 (]: Creating new relation stg_staff
[0m11:46:08.263748 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

            

    
        create table `adw02_stag`.`stg_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
          )
        
        ...
[0m11:46:08.277483 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:46:08.282601 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

    select name, type from system.columns where table = 'stg_staff'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:46:08.286071 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:46:08.288024 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff"
[0m11:46:08.288815 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_staff`
        ("staff_key", "staff_first_name", "staff_last_name", "staff_email", "staff_active", "staff_username", "staff_password", "staff_last_update", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
  ...
[0m11:46:08.304563 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:46:08.306149 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b6f7a99-c9e8-4e92-99bf-b2c46333044f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78a8078440>]}
[0m11:46:08.306692 [info ] [Thread-1 (]: 4 of 5 OK created sql table model `adw02_stag`.`stg_staff` ..................... [[32mOK[0m in 0.05s]
[0m11:46:08.307209 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m11:46:08.307634 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m11:46:08.308029 [info ] [Thread-1 (]: 5 of 5 START sql table model `adw02_stag`.`stg_store` .......................... [RUN]
[0m11:46:08.308512 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_store)
[0m11:46:08.308824 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m11:46:08.310394 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m11:46:08.310962 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m11:46:08.313206 [debug] [Thread-1 (]: Creating new relation stg_store
[0m11:46:08.314266 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

            

    
        create table `adw02_stag`.`stg_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila_proxy.address a ON s.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
    JOIN sakila_proxy.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
          )
        
        ...
[0m11:46:08.332154 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:46:08.334503 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

    select name, type from system.columns where table = 'stg_store'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:46:08.337660 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:46:08.339723 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store"
[0m11:46:08.340260 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_store`
        ("store_key", "store_address", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")WITH source AS (
    SELECT * FROM sakila_proxy.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila_proxy.address a ON s.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
    JOIN sakila_proxy.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
  ...
[0m11:46:08.396872 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m11:46:08.398514 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6b6f7a99-c9e8-4e92-99bf-b2c46333044f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78b0d4ad50>]}
[0m11:46:08.399203 [info ] [Thread-1 (]: 5 of 5 OK created sql table model `adw02_stag`.`stg_store` ..................... [[32mOK[0m in 0.09s]
[0m11:46:08.399825 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m11:46:08.401015 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:46:08.401425 [debug] [MainThread]: Connection 'model.sakstar.stg_store' was left open.
[0m11:46:08.401701 [debug] [MainThread]: On model.sakstar.stg_store: Close
[0m11:46:08.402086 [info ] [MainThread]: 
[0m11:46:08.402619 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 0.86 seconds (0.86s).
[0m11:46:08.404791 [debug] [MainThread]: Command end result
[0m11:46:08.434568 [info ] [MainThread]: 
[0m11:46:08.434966 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m11:46:08.435372 [info ] [MainThread]: 
[0m11:46:08.436045 [error] [MainThread]:   Database Error in model stg_rental (models/staging/rental/stg_rental.sql)
  Code: 42.
  DB::Exception: An incorrect number of arguments was specified for function 'dateDiff'. Expected 3 mandatory arguments and 1 optional argument, got 2 arguments: In scope WITH source AS (SELECT * FROM sakila_proxy.rental), inventory AS (SELECT * FROM sakila_proxy.inventory) SELECT r.rental_id AS rental_key, r.customer_id AS customer_key, i.film_id AS film_key, r.staff_id AS staff_key, i.store_id AS store_key, r.rental_date, r.return_date, i.inventory_id, dateDiff(r.return_date, r.rental_date) AS rental_duration, r.last_update FROM source AS r INNER JOIN inventory AS i ON r.inventory_id = i.inventory_id. Stack trace:
  
  0. DB::Exception::Exception(DB::Exception::MessageMasked&&, int, bool) @ 0x000000000f2be35b
  1. DB::Exception::Exception(PreformattedMessage&&, int) @ 0x0000000009c73bec
  2. DB::Exception::Exception<String, String&, String>(int, FormatStringHelperImpl<std::type_identity<String>::type, std::type_identity<String&>::type, std::type_identity<String>::type>, String&&, String&, String&&) @ 0x0000000011997beb
  3. DB::validateFunctionArguments(DB::IFunction const&, std::vector<DB::ColumnWithTypeAndName, std::allocator<DB::ColumnWithTypeAndName>> const&, std::vector<DB::FunctionArgumentDescriptor, std::allocator<DB::FunctionArgumentDescriptor>> const&, std::vector<DB::FunctionArgumentDescriptor, std::allocator<DB::FunctionArgumentDescriptor>> const&) @ 0x0000000011997abf
  4. DB::(anonymous namespace)::FunctionDateDiff<true>::getReturnTypeImpl(std::vector<DB::ColumnWithTypeAndName, std::allocator<DB::ColumnWithTypeAndName>> const&) const @ 0x000000000ad638b3
  5. DB::IFunctionOverloadResolver::getReturnTypeWithoutLowCardinality(std::vector<DB::ColumnWithTypeAndName, std::allocator<DB::ColumnWithTypeAndName>> const&) const @ 0x0000000011987310
  6. DB::IFunctionOverloadResolver::build(std::vector<DB::ColumnWithTypeAndName, std::allocator<DB::ColumnWithTypeAndName>> const&) const @ 0x0000000011987daa
  7. DB::QueryAnalyzer::resolveFunction(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x00000000128f773e
  8. DB::QueryAnalyzer::resolveExpressionNode(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool, bool) @ 0x00000000128dbd20
  9. DB::QueryAnalyzer::resolveExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&, bool, bool) @ 0x00000000128db154
  10. DB::QueryAnalyzer::resolveProjectionExpressionNodeList(std::shared_ptr<DB::IQueryTreeNode>&, DB::IdentifierResolveScope&) @ 0x000000001290bba7
  11. DB::QueryAnalyzer::resolveQuery(std::shared_ptr<DB::IQueryTreeNode> const&, DB::IdentifierResolveScope&) @ 0x00000000128d18ba
  12. DB::QueryAnalyzer::resolve(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::IQueryTreeNode> const&, std::shared_ptr<DB::Context const>) @ 0x00000000128cfb8c
  13. DB::QueryAnalysisPass::run(std::shared_ptr<DB::IQueryTreeNode>&, std::shared_ptr<DB::Context const>) @ 0x00000000128cf3f3
  14. DB::QueryTreePassManager::run(std::shared_ptr<DB::IQueryTreeNode>) @ 0x0000000012924db6
  15. DB::buildQueryTreeAndRunPasses(std::shared_ptr<DB::IAST> const&, DB::SelectQueryOptions const&, std::shared_ptr<DB::Context const> const&, std::shared_ptr<DB::IStorage> const&) (.llvm.5923817706791937394) @ 0x0000000013234fe5
  16. DB::InterpreterSelectQueryAnalyzer::InterpreterSelectQueryAnalyzer(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&, std::vector<String, std::allocator<String>> const&) @ 0x0000000013232f7c
  17. DB::InterpreterSelectQueryAnalyzer::getSampleBlock(std::shared_ptr<DB::IAST> const&, std::shared_ptr<DB::Context const> const&, DB::SelectQueryOptions const&) @ 0x0000000013235419
  18. DB::InterpreterCreateQuery::getTablePropertiesAndNormalizeCreateQuery(DB::ASTCreateQuery&, DB::LoadingStrictnessLevel) const @ 0x00000000131981de
  19. DB::InterpreterCreateQuery::createTable(DB::ASTCreateQuery&) @ 0x00000000131a0c2a
  20. DB::InterpreterCreateQuery::execute() @ 0x00000000131b6678
  21. DB::executeQueryImpl(char const*, char const*, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum, DB::ReadBuffer*, std::shared_ptr<DB::IAST>&) @ 0x00000000135904e8
  22. DB::executeQuery(String const&, std::shared_ptr<DB::Context>, DB::QueryFlags, DB::QueryProcessingStage::Enum) @ 0x0000000013589be6
  23. DB::TCPHandler::runImpl() @ 0x00000000148e9cfe
  24. DB::TCPHandler::run() @ 0x00000000149089f9
  25. Poco::Net::TCPServerConnection::start() @ 0x000000001800e967
  26. Poco::Net::TCPServerDispatcher::run() @ 0x000000001800edb9
  27. Poco::PooledThread::run() @ 0x0000000017fda0db
  28. Poco::ThreadImpl::runnableEntry(void*) @ 0x0000000017fd85bd
  29. ? @ 0x00007fb490894ac3
  30. ? @ 0x00007fb490926850
[0m11:46:08.436542 [info ] [MainThread]: 
[0m11:46:08.436871 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
[0m11:46:08.437577 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": false, "command_wall_clock_time": 1.7964711, "process_in_blocks": "0", "process_kernel_time": 0.154938, "process_mem_max_rss": "143456", "process_out_blocks": "4432", "process_user_time": 2.422927}
[0m11:46:08.437936 [debug] [MainThread]: Command `dbt run` failed at 11:46:08.437848 after 1.80 seconds
[0m11:46:08.438253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78b2410d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78a80596d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7d78a8059670>]}
[0m11:46:08.438563 [debug] [MainThread]: Flushing usage events
[0m11:49:57.458485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x741741d92120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74173fcb5590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74173fcb5450>]}


============================== 11:49:57.461201 | 12c436de-33a3-4fdf-a8a4-a9ff97cc2257 ==============================
[0m11:49:57.461201 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:49:57.461682 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar', 'fail_fast': 'False', 'debug': 'False', 'log_path': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/logs', 'version_check': 'True', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'log_format': 'default', 'introspect': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m11:49:57.601773 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '12c436de-33a3-4fdf-a8a4-a9ff97cc2257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x741740ce9cd0>]}
[0m11:49:57.650581 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '12c436de-33a3-4fdf-a8a4-a9ff97cc2257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74173fb3f570>]}
[0m11:49:57.651162 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:49:57.729663 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:49:57.831859 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:49:57.832408 [debug] [MainThread]: Partial parsing: updated file: sakstar://models/staging/rental/stg_rental.sql
[0m11:49:58.021040 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m11:49:58.021485 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '12c436de-33a3-4fdf-a8a4-a9ff97cc2257', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74173faff750>]}
[0m11:49:58.158436 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.sakstar.marts
[0m11:49:58.169519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '12c436de-33a3-4fdf-a8a4-a9ff97cc2257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74173f616990>]}
[0m11:49:58.254585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '12c436de-33a3-4fdf-a8a4-a9ff97cc2257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74173dce8750>]}
[0m11:49:58.254979 [info ] [MainThread]: Found 5 models, 10 data tests, 10 sources, 608 macros
[0m11:49:58.255390 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '12c436de-33a3-4fdf-a8a4-a9ff97cc2257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74173f7757e0>]}
[0m11:49:58.257190 [info ] [MainThread]: 
[0m11:49:58.257855 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:49:58.263319 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:49:58.272249 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:49:58.513952 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:49:58.516427 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:49:58.537540 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__adw02_stag)
[0m11:49:58.542387 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw02_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw02_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw02_stag'
      

  ...
[0m11:49:58.554831 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:49:58.556276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '12c436de-33a3-4fdf-a8a4-a9ff97cc2257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74173de26690>]}
[0m11:49:58.556740 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m11:49:58.557052 [info ] [MainThread]: 
[0m11:49:58.559197 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m11:49:58.559737 [info ] [Thread-1 (]: 1 of 5 START sql table model `adw02_stag`.`stg_customer` ....................... [RUN]
[0m11:49:58.560224 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw02_stag, now model.sakstar.stg_customer)
[0m11:49:58.560629 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m11:49:58.566640 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m11:49:58.567204 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m11:49:58.583977 [debug] [Thread-1 (]: Creating new relation stg_customer
[0m11:49:58.613376 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

            

    
        create table `adw02_stag`.`stg_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
          )
        
        ...
[0m11:49:58.632445 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:49:58.648514 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

    select name, type from system.columns where table = 'stg_customer'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:49:58.652691 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:49:58.657523 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m11:49:58.658129 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_customer`
        ("customer_key", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_created", "customer_address", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_last_update", "c.address_id", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
  ...
[0m11:49:58.708967 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m11:49:58.727150 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12c436de-33a3-4fdf-a8a4-a9ff97cc2257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74173f4b7ee0>]}
[0m11:49:58.727806 [info ] [Thread-1 (]: 1 of 5 OK created sql table model `adw02_stag`.`stg_customer` .................. [[32mOK[0m in 0.17s]
[0m11:49:58.728479 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m11:49:58.728885 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film
[0m11:49:58.729399 [info ] [Thread-1 (]: 2 of 5 START sql table model `adw02_stag`.`stg_film` ........................... [RUN]
[0m11:49:58.729816 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_film)
[0m11:49:58.730176 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film
[0m11:49:58.731845 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_film"
[0m11:49:58.732420 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_film
[0m11:49:58.734521 [debug] [Thread-1 (]: Creating new relation stg_film
[0m11:49:58.735743 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

            

    
        create table `adw02_stag`.`stg_film`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.film
)
SELECT
    f.film_id as film_key,
    f.title as film_title,
    f.description as film_description,
    f.release_year as film_release_year,
    l.name as film_language,
    CASE WHEN f.original_language_id IS NOT NULL THEN 1 ELSE 0 END as film_has_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.length as film_duration,
    f.replacement_cost as film_replacement_cost,
    f.rating as film_rating,
    f.special_features as film_special_features,
    f.last_update as film_last_update
FROM source f
JOIN sakila_proxy.language l ON f.language_id = l.language_id
          )
        
        ...
[0m11:49:58.749514 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:49:58.751854 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

    select name, type from system.columns where table = 'stg_film'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:49:58.755185 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:49:58.757414 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_film"
[0m11:49:58.757968 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_film`
        ("film_key", "film_title", "film_description", "film_release_year", "film_language", "film_has_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_last_update")WITH source AS (
    SELECT * FROM sakila_proxy.film
)
SELECT
    f.film_id as film_key,
    f.title as film_title,
    f.description as film_description,
    f.release_year as film_release_year,
    l.name as film_language,
    CASE WHEN f.original_language_id IS NOT NULL THEN 1 ELSE 0 END as film_has_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.length as film_duration,
    f.replacement_cost as film_replacement_cost,
    f.rating as film_rating,
    f.special_features as film_special_features,
    f.last_update as film_last_update
FROM source f
JOIN sakila_proxy.language l ON f.language_id = l.language_id
  ...
[0m11:49:58.786333 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m11:49:58.787978 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12c436de-33a3-4fdf-a8a4-a9ff97cc2257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x741737aa0410>]}
[0m11:49:58.788528 [info ] [Thread-1 (]: 2 of 5 OK created sql table model `adw02_stag`.`stg_film` ...................... [[32mOK[0m in 0.06s]
[0m11:49:58.789067 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film
[0m11:49:58.789460 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rental
[0m11:49:58.789900 [info ] [Thread-1 (]: 3 of 5 START sql table model `adw02_stag`.`stg_rental` ......................... [RUN]
[0m11:49:58.790376 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film, now model.sakstar.stg_rental)
[0m11:49:58.790730 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rental
[0m11:49:58.792683 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_rental"
[0m11:49:58.793278 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_rental
[0m11:49:58.795039 [debug] [Thread-1 (]: Creating new relation stg_rental
[0m11:49:58.795976 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

            

    
        create table `adw02_stag`.`stg_rental`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.rental
),
inventory AS (
    SELECT * FROM sakila_proxy.inventory
)
SELECT
    r.rental_id as rental_key,
    r.customer_id as customer_key,
    i.film_id as film_key,
    r.staff_id as staff_key,
    i.store_id as store_key,
    r.rental_date,
    r.return_date,
    i.inventory_id,
    DATEDIFF('second', r.return_date, r.rental_date) as rental_duration,
    r.last_update
FROM source r
JOIN inventory i ON r.inventory_id = i.inventory_id
          )
        
        ...
[0m11:49:58.809898 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:49:58.813147 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

    select name, type from system.columns where table = 'stg_rental'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:49:58.816777 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:49:58.818940 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_rental"
[0m11:49:58.819515 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_rental`
        ("rental_key", "customer_key", "film_key", "staff_key", "store_key", "rental_date", "return_date", "i.inventory_id", "rental_duration", "last_update")WITH source AS (
    SELECT * FROM sakila_proxy.rental
),
inventory AS (
    SELECT * FROM sakila_proxy.inventory
)
SELECT
    r.rental_id as rental_key,
    r.customer_id as customer_key,
    i.film_id as film_key,
    r.staff_id as staff_key,
    i.store_id as store_key,
    r.rental_date,
    r.return_date,
    i.inventory_id,
    DATEDIFF('second', r.return_date, r.rental_date) as rental_duration,
    r.last_update
FROM source r
JOIN inventory i ON r.inventory_id = i.inventory_id
  ...
[0m11:49:58.860478 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m11:49:58.862188 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12c436de-33a3-4fdf-a8a4-a9ff97cc2257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x741737baaf50>]}
[0m11:49:58.862691 [info ] [Thread-1 (]: 3 of 5 OK created sql table model `adw02_stag`.`stg_rental` .................... [[32mOK[0m in 0.07s]
[0m11:49:58.863185 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rental
[0m11:49:58.863554 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m11:49:58.864002 [info ] [Thread-1 (]: 4 of 5 START sql table model `adw02_stag`.`stg_staff` .......................... [RUN]
[0m11:49:58.864383 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rental, now model.sakstar.stg_staff)
[0m11:49:58.864699 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m11:49:58.866258 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m11:49:58.866833 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m11:49:58.869279 [debug] [Thread-1 (]: Creating new relation stg_staff
[0m11:49:58.870441 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

            

    
        create table `adw02_stag`.`stg_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
          )
        
        ...
[0m11:49:58.881942 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:49:58.884485 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

    select name, type from system.columns where table = 'stg_staff'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:49:58.887967 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:49:58.890071 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff"
[0m11:49:58.890786 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_staff`
        ("staff_key", "staff_first_name", "staff_last_name", "staff_email", "staff_active", "staff_username", "staff_password", "staff_last_update", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
  ...
[0m11:49:58.904686 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:49:58.906245 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12c436de-33a3-4fdf-a8a4-a9ff97cc2257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74173f4b1d30>]}
[0m11:49:58.906916 [info ] [Thread-1 (]: 4 of 5 OK created sql table model `adw02_stag`.`stg_staff` ..................... [[32mOK[0m in 0.04s]
[0m11:49:58.907425 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m11:49:58.907799 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m11:49:58.908256 [info ] [Thread-1 (]: 5 of 5 START sql table model `adw02_stag`.`stg_store` .......................... [RUN]
[0m11:49:58.908814 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_store)
[0m11:49:58.909196 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m11:49:58.911178 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m11:49:58.911737 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m11:49:58.913527 [debug] [Thread-1 (]: Creating new relation stg_store
[0m11:49:58.914765 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

            

    
        create table `adw02_stag`.`stg_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila_proxy.address a ON s.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
    JOIN sakila_proxy.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
          )
        
        ...
[0m11:49:58.932016 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:49:58.937221 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

    select name, type from system.columns where table = 'stg_store'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:49:58.940693 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:49:58.942635 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store"
[0m11:49:58.943161 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_store`
        ("store_key", "store_address", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")WITH source AS (
    SELECT * FROM sakila_proxy.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila_proxy.address a ON s.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
    JOIN sakila_proxy.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
  ...
[0m11:49:59.000197 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m11:49:59.001972 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12c436de-33a3-4fdf-a8a4-a9ff97cc2257', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x741737bee870>]}
[0m11:49:59.002530 [info ] [Thread-1 (]: 5 of 5 OK created sql table model `adw02_stag`.`stg_store` ..................... [[32mOK[0m in 0.09s]
[0m11:49:59.003064 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m11:49:59.004210 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:49:59.004543 [debug] [MainThread]: Connection 'model.sakstar.stg_store' was left open.
[0m11:49:59.004862 [debug] [MainThread]: On model.sakstar.stg_store: Close
[0m11:49:59.005460 [info ] [MainThread]: 
[0m11:49:59.005927 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 0.75 seconds (0.75s).
[0m11:49:59.007267 [debug] [MainThread]: Command end result
[0m11:49:59.042810 [info ] [MainThread]: 
[0m11:49:59.043189 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:49:59.043542 [info ] [MainThread]: 
[0m11:49:59.043857 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m11:49:59.044569 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.6270511, "process_in_blocks": "0", "process_kernel_time": 0.13996, "process_mem_max_rss": "143084", "process_out_blocks": "4424", "process_user_time": 2.270858}
[0m11:49:59.044963 [debug] [MainThread]: Command `dbt run` succeeded at 11:49:59.044870 after 1.63 seconds
[0m11:49:59.045333 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74173f60f7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74173fb34770>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x741736123b30>]}
[0m11:49:59.045882 [debug] [MainThread]: Flushing usage events
[0m11:51:27.261486 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a438877e120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a438668d590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a438668d450>]}


============================== 11:51:27.264117 | d5356824-9196-421b-b08d-a78a51f56674 ==============================
[0m11:51:27.264117 [info ] [MainThread]: Running with dbt=1.8.9
[0m11:51:27.264608 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar', 'debug': 'False', 'warn_error': 'None', 'log_path': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/logs', 'fail_fast': 'False', 'version_check': 'True', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'introspect': 'True', 'log_format': 'default', 'invocation_command': 'dbt run', 'target_path': 'None', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True'}
[0m11:51:27.408653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'd5356824-9196-421b-b08d-a78a51f56674', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a43875f1cd0>]}
[0m11:51:27.457020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'd5356824-9196-421b-b08d-a78a51f56674', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a4386507790>]}
[0m11:51:27.457624 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m11:51:27.537124 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m11:51:27.640442 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m11:51:27.641028 [debug] [MainThread]: Partial parsing: updated file: sakstar://models/staging/rental/stg_rental.sql
[0m11:51:27.835245 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m11:51:27.835668 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'd5356824-9196-421b-b08d-a78a51f56674', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a43864dfb50>]}
[0m11:51:27.977478 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.sakstar.marts
[0m11:51:27.989264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd5356824-9196-421b-b08d-a78a51f56674', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a4385e66c60>]}
[0m11:51:28.080068 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd5356824-9196-421b-b08d-a78a51f56674', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a43846e4750>]}
[0m11:51:28.080827 [info ] [MainThread]: Found 5 models, 10 data tests, 10 sources, 608 macros
[0m11:51:28.081381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd5356824-9196-421b-b08d-a78a51f56674', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a438466fad0>]}
[0m11:51:28.084354 [info ] [MainThread]: 
[0m11:51:28.085084 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m11:51:28.092572 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m11:51:28.101508 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m11:51:28.343643 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m11:51:28.346099 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:28.367242 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__adw02_stag)
[0m11:51:28.372166 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw02_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw02_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw02_stag'
      

  ...
[0m11:51:28.385049 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:51:28.386596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd5356824-9196-421b-b08d-a78a51f56674', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a4386052690>]}
[0m11:51:28.387051 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m11:51:28.387360 [info ] [MainThread]: 
[0m11:51:28.389492 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m11:51:28.389962 [info ] [Thread-1 (]: 1 of 5 START sql table model `adw02_stag`.`stg_customer` ....................... [RUN]
[0m11:51:28.390372 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw02_stag, now model.sakstar.stg_customer)
[0m11:51:28.390693 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m11:51:28.397365 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m11:51:28.397948 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m11:51:28.415251 [debug] [Thread-1 (]: Creating new relation stg_customer
[0m11:51:28.446052 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

            

    
        create table `adw02_stag`.`stg_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
          )
        
        ...
[0m11:51:28.466550 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:51:28.481708 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

    select name, type from system.columns where table = 'stg_customer'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:51:28.485572 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:28.489688 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m11:51:28.490257 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_customer`
        ("customer_key", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_created", "customer_address", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_last_update", "c.address_id", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
  ...
[0m11:51:28.540418 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m11:51:28.557695 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5356824-9196-421b-b08d-a78a51f56674', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a4385e7fe30>]}
[0m11:51:28.558268 [info ] [Thread-1 (]: 1 of 5 OK created sql table model `adw02_stag`.`stg_customer` .................. [[32mOK[0m in 0.17s]
[0m11:51:28.558831 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m11:51:28.559232 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film
[0m11:51:28.559695 [info ] [Thread-1 (]: 2 of 5 START sql table model `adw02_stag`.`stg_film` ........................... [RUN]
[0m11:51:28.560123 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_film)
[0m11:51:28.560483 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film
[0m11:51:28.562012 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_film"
[0m11:51:28.562710 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_film
[0m11:51:28.564959 [debug] [Thread-1 (]: Creating new relation stg_film
[0m11:51:28.566053 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

            

    
        create table `adw02_stag`.`stg_film`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.film
)
SELECT
    f.film_id as film_key,
    f.title as film_title,
    f.description as film_description,
    f.release_year as film_release_year,
    l.name as film_language,
    CASE WHEN f.original_language_id IS NOT NULL THEN 1 ELSE 0 END as film_has_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.length as film_duration,
    f.replacement_cost as film_replacement_cost,
    f.rating as film_rating,
    f.special_features as film_special_features,
    f.last_update as film_last_update
FROM source f
JOIN sakila_proxy.language l ON f.language_id = l.language_id
          )
        
        ...
[0m11:51:28.580662 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:51:28.583063 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

    select name, type from system.columns where table = 'stg_film'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:51:28.586401 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:28.588611 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_film"
[0m11:51:28.589190 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_film`
        ("film_key", "film_title", "film_description", "film_release_year", "film_language", "film_has_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_last_update")WITH source AS (
    SELECT * FROM sakila_proxy.film
)
SELECT
    f.film_id as film_key,
    f.title as film_title,
    f.description as film_description,
    f.release_year as film_release_year,
    l.name as film_language,
    CASE WHEN f.original_language_id IS NOT NULL THEN 1 ELSE 0 END as film_has_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.length as film_duration,
    f.replacement_cost as film_replacement_cost,
    f.rating as film_rating,
    f.special_features as film_special_features,
    f.last_update as film_last_update
FROM source f
JOIN sakila_proxy.language l ON f.language_id = l.language_id
  ...
[0m11:51:28.616813 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m11:51:28.618567 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5356824-9196-421b-b08d-a78a51f56674', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a437e44c370>]}
[0m11:51:28.619111 [info ] [Thread-1 (]: 2 of 5 OK created sql table model `adw02_stag`.`stg_film` ...................... [[32mOK[0m in 0.06s]
[0m11:51:28.619666 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film
[0m11:51:28.620055 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rental
[0m11:51:28.620506 [info ] [Thread-1 (]: 3 of 5 START sql table model `adw02_stag`.`stg_rental` ......................... [RUN]
[0m11:51:28.620912 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film, now model.sakstar.stg_rental)
[0m11:51:28.621368 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rental
[0m11:51:28.623431 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_rental"
[0m11:51:28.624013 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_rental
[0m11:51:28.625925 [debug] [Thread-1 (]: Creating new relation stg_rental
[0m11:51:28.626957 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

            

    
        create table `adw02_stag`.`stg_rental`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.rental
),
inventory AS (
    SELECT * FROM sakila_proxy.inventory
)
SELECT
    r.rental_id as rental_key,
    r.customer_id as customer_key,
    i.film_id as film_key,
    r.staff_id as staff_key,
    i.store_id as store_key,
    r.rental_date,
    r.return_date,
    i.inventory_id,
    DATEDIFF('second', r.rental_date, r.return_date) as rental_duration,
    r.last_update
FROM source r
JOIN inventory i ON r.inventory_id = i.inventory_id
          )
        
        ...
[0m11:51:28.639979 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:51:28.642584 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

    select name, type from system.columns where table = 'stg_rental'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:51:28.645735 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:28.647735 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_rental"
[0m11:51:28.648263 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_rental`
        ("rental_key", "customer_key", "film_key", "staff_key", "store_key", "rental_date", "return_date", "i.inventory_id", "rental_duration", "last_update")WITH source AS (
    SELECT * FROM sakila_proxy.rental
),
inventory AS (
    SELECT * FROM sakila_proxy.inventory
)
SELECT
    r.rental_id as rental_key,
    r.customer_id as customer_key,
    i.film_id as film_key,
    r.staff_id as staff_key,
    i.store_id as store_key,
    r.rental_date,
    r.return_date,
    i.inventory_id,
    DATEDIFF('second', r.rental_date, r.return_date) as rental_duration,
    r.last_update
FROM source r
JOIN inventory i ON r.inventory_id = i.inventory_id
  ...
[0m11:51:28.688661 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m11:51:28.690298 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5356824-9196-421b-b08d-a78a51f56674', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a437e55afd0>]}
[0m11:51:28.690820 [info ] [Thread-1 (]: 3 of 5 OK created sql table model `adw02_stag`.`stg_rental` .................... [[32mOK[0m in 0.07s]
[0m11:51:28.691333 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rental
[0m11:51:28.691703 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m11:51:28.692111 [info ] [Thread-1 (]: 4 of 5 START sql table model `adw02_stag`.`stg_staff` .......................... [RUN]
[0m11:51:28.692542 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rental, now model.sakstar.stg_staff)
[0m11:51:28.692863 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m11:51:28.694465 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m11:51:28.695013 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m11:51:28.697266 [debug] [Thread-1 (]: Creating new relation stg_staff
[0m11:51:28.698292 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

            

    
        create table `adw02_stag`.`stg_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
          )
        
        ...
[0m11:51:28.710952 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:51:28.713492 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

    select name, type from system.columns where table = 'stg_staff'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:51:28.716795 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:28.718868 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff"
[0m11:51:28.719607 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_staff`
        ("staff_key", "staff_first_name", "staff_last_name", "staff_email", "staff_active", "staff_username", "staff_password", "staff_last_update", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
  ...
[0m11:51:28.733493 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m11:51:28.735294 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5356824-9196-421b-b08d-a78a51f56674', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a4385ea9da0>]}
[0m11:51:28.735845 [info ] [Thread-1 (]: 4 of 5 OK created sql table model `adw02_stag`.`stg_staff` ..................... [[32mOK[0m in 0.04s]
[0m11:51:28.736477 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m11:51:28.736863 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m11:51:28.737388 [info ] [Thread-1 (]: 5 of 5 START sql table model `adw02_stag`.`stg_store` .......................... [RUN]
[0m11:51:28.737820 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_store)
[0m11:51:28.738177 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m11:51:28.740188 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m11:51:28.740767 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m11:51:28.742651 [debug] [Thread-1 (]: Creating new relation stg_store
[0m11:51:28.743705 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

            

    
        create table `adw02_stag`.`stg_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila_proxy.address a ON s.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
    JOIN sakila_proxy.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
          )
        
        ...
[0m11:51:28.761897 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m11:51:28.767514 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

    select name, type from system.columns where table = 'stg_store'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m11:51:28.771309 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m11:51:28.773335 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store"
[0m11:51:28.773915 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_store`
        ("store_key", "store_address", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")WITH source AS (
    SELECT * FROM sakila_proxy.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila_proxy.address a ON s.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
    JOIN sakila_proxy.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
  ...
[0m11:51:28.832724 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m11:51:28.834339 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd5356824-9196-421b-b08d-a78a51f56674', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a437e5136b0>]}
[0m11:51:28.834880 [info ] [Thread-1 (]: 5 of 5 OK created sql table model `adw02_stag`.`stg_store` ..................... [[32mOK[0m in 0.10s]
[0m11:51:28.835492 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m11:51:28.836554 [debug] [MainThread]: Connection 'master' was properly closed.
[0m11:51:28.836835 [debug] [MainThread]: Connection 'model.sakstar.stg_store' was left open.
[0m11:51:28.837334 [debug] [MainThread]: On model.sakstar.stg_store: Close
[0m11:51:28.837750 [info ] [MainThread]: 
[0m11:51:28.838162 [info ] [MainThread]: Finished running 5 table models in 0 hours 0 minutes and 0.75 seconds (0.75s).
[0m11:51:28.839452 [debug] [MainThread]: Command end result
[0m11:51:28.875542 [info ] [MainThread]: 
[0m11:51:28.875936 [info ] [MainThread]: [32mCompleted successfully[0m
[0m11:51:28.876231 [info ] [MainThread]: 
[0m11:51:28.876645 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
[0m11:51:28.877670 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.6564304, "process_in_blocks": "0", "process_kernel_time": 0.158676, "process_mem_max_rss": "143032", "process_out_blocks": "4424", "process_user_time": 2.297694}
[0m11:51:28.878201 [debug] [MainThread]: Command `dbt run` succeeded at 11:51:28.878082 after 1.66 seconds
[0m11:51:28.878653 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a43875daf90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a437caeba10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7a437caeb9b0>]}
[0m11:51:28.879045 [debug] [MainThread]: Flushing usage events
[0m12:02:03.930208 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d8d192120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d8b0b5590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d8b0b5450>]}


============================== 12:02:03.934508 | 9d896956-3a5c-4d1e-aed1-4df5cf8109bb ==============================
[0m12:02:03.934508 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:02:03.935444 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/logs', 'debug': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'static_parser': 'True', 'introspect': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:02:04.170191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '9d896956-3a5c-4d1e-aed1-4df5cf8109bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d8c0e9cd0>]}
[0m12:02:04.250250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '9d896956-3a5c-4d1e-aed1-4df5cf8109bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d8af27790>]}
[0m12:02:04.251205 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:02:04.392497 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:02:04.561670 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 0 files changed.
[0m12:02:04.562404 [debug] [MainThread]: Partial parsing: added file: sakstar://models/marts/dim/dim_customer/dim_customer.yml
[0m12:02:04.562902 [debug] [MainThread]: Partial parsing: added file: sakstar://models/marts/dim/dim_customer/dim_customer.sql
[0m12:02:04.852908 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m12:02:04.853566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '9d896956-3a5c-4d1e-aed1-4df5cf8109bb', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d8ab4a050>]}
[0m12:02:05.084814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9d896956-3a5c-4d1e-aed1-4df5cf8109bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d8a876c60>]}
[0m12:02:05.219467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9d896956-3a5c-4d1e-aed1-4df5cf8109bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d890fcbb0>]}
[0m12:02:05.220068 [info ] [MainThread]: Found 6 models, 12 data tests, 10 sources, 608 macros
[0m12:02:05.220590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9d896956-3a5c-4d1e-aed1-4df5cf8109bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d89203ba0>]}
[0m12:02:05.223518 [info ] [MainThread]: 
[0m12:02:05.224412 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:02:05.233233 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:02:05.246990 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:02:05.589849 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:02:05.593144 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:02:05.628480 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:02:05.632411 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:02:05.634747 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now create__adw02_star)
[0m12:02:05.635453 [debug] [ThreadPool]: Creating schema "schema: "adw02_star"
"
[0m12:02:05.644660 [debug] [ThreadPool]: dbt_clickhouse adapter: On create__adw02_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "create__adw02_star"} */
create database if not exists `adw02_star`
        
  
        
  ...
[0m12:02:05.651591 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:02:05.654262 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly create__adw02_star, now list__adw02_star)
[0m12:02:05.661816 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw02_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw02_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw02_star'
      

  ...
[0m12:02:05.677987 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:02:05.679987 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw02_star, now list__adw02_stag)
[0m12:02:05.682257 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw02_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw02_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw02_stag'
      

  ...
[0m12:02:05.696667 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:02:05.698875 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9d896956-3a5c-4d1e-aed1-4df5cf8109bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d89116810>]}
[0m12:02:05.699594 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m12:02:05.700050 [info ] [MainThread]: 
[0m12:02:05.703645 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m12:02:05.704489 [info ] [Thread-1 (]: 1 of 6 START sql table model `adw02_stag`.`stg_customer` ....................... [RUN]
[0m12:02:05.705168 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw02_stag, now model.sakstar.stg_customer)
[0m12:02:05.705773 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m12:02:05.714906 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m12:02:05.715805 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m12:02:05.744203 [debug] [Thread-1 (]: Creating new relation stg_customer
[0m12:02:05.788241 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

            

    
        create table `adw02_stag`.`stg_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
          )
        
        ...
[0m12:02:05.813474 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:02:05.836963 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

    select name, type from system.columns where table = 'stg_customer'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:02:05.841575 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:02:05.847673 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m12:02:05.848550 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_customer`
        ("customer_key", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_created", "customer_address", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_last_update", "c.address_id", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
  ...
[0m12:02:05.926649 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.08 seconds
[0m12:02:05.954199 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d896956-3a5c-4d1e-aed1-4df5cf8109bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d8a88f070>]}
[0m12:02:05.955054 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `adw02_stag`.`stg_customer` .................. [[32mOK[0m in 0.25s]
[0m12:02:05.955879 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m12:02:05.956470 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film
[0m12:02:05.957115 [info ] [Thread-1 (]: 2 of 6 START sql table model `adw02_stag`.`stg_film` ........................... [RUN]
[0m12:02:05.957783 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_film)
[0m12:02:05.958392 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film
[0m12:02:05.960831 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_film"
[0m12:02:05.961911 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_film
[0m12:02:05.965924 [debug] [Thread-1 (]: Creating new relation stg_film
[0m12:02:05.967849 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

            

    
        create table `adw02_stag`.`stg_film`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.film
)
SELECT
    f.film_id as film_key,
    f.title as film_title,
    f.description as film_description,
    f.release_year as film_release_year,
    l.name as film_language,
    CASE WHEN f.original_language_id IS NOT NULL THEN 1 ELSE 0 END as film_has_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.length as film_duration,
    f.replacement_cost as film_replacement_cost,
    f.rating as film_rating,
    f.special_features as film_special_features,
    f.last_update as film_last_update
FROM source f
JOIN sakila_proxy.language l ON f.language_id = l.language_id
          )
        
        ...
[0m12:02:05.989234 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:02:05.992949 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

    select name, type from system.columns where table = 'stg_film'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:02:05.997894 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:02:06.001383 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_film"
[0m12:02:06.002200 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_film`
        ("film_key", "film_title", "film_description", "film_release_year", "film_language", "film_has_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_last_update")WITH source AS (
    SELECT * FROM sakila_proxy.film
)
SELECT
    f.film_id as film_key,
    f.title as film_title,
    f.description as film_description,
    f.release_year as film_release_year,
    l.name as film_language,
    CASE WHEN f.original_language_id IS NOT NULL THEN 1 ELSE 0 END as film_has_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.length as film_duration,
    f.replacement_cost as film_replacement_cost,
    f.rating as film_rating,
    f.special_features as film_special_features,
    f.last_update as film_last_update
FROM source f
JOIN sakila_proxy.language l ON f.language_id = l.language_id
  ...
[0m12:02:06.043516 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m12:02:06.045883 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d896956-3a5c-4d1e-aed1-4df5cf8109bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d82ea6710>]}
[0m12:02:06.046657 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `adw02_stag`.`stg_film` ...................... [[32mOK[0m in 0.09s]
[0m12:02:06.047440 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film
[0m12:02:06.047989 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rental
[0m12:02:06.048731 [info ] [Thread-1 (]: 3 of 6 START sql table model `adw02_stag`.`stg_rental` ......................... [RUN]
[0m12:02:06.049464 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film, now model.sakstar.stg_rental)
[0m12:02:06.049965 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rental
[0m12:02:06.052934 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_rental"
[0m12:02:06.053846 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_rental
[0m12:02:06.056777 [debug] [Thread-1 (]: Creating new relation stg_rental
[0m12:02:06.058322 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

            

    
        create table `adw02_stag`.`stg_rental`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.rental
),
inventory AS (
    SELECT * FROM sakila_proxy.inventory
)
SELECT
    r.rental_id as rental_key,
    r.customer_id as customer_key,
    i.film_id as film_key,
    r.staff_id as staff_key,
    i.store_id as store_key,
    r.rental_date,
    r.return_date,
    i.inventory_id,
    DATEDIFF('second', r.rental_date, r.return_date) as rental_duration,
    r.last_update
FROM source r
JOIN inventory i ON r.inventory_id = i.inventory_id
          )
        
        ...
[0m12:02:06.077686 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:02:06.081506 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

    select name, type from system.columns where table = 'stg_rental'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:02:06.085958 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:02:06.089168 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_rental"
[0m12:02:06.090104 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_rental`
        ("rental_key", "customer_key", "film_key", "staff_key", "store_key", "rental_date", "return_date", "i.inventory_id", "rental_duration", "last_update")WITH source AS (
    SELECT * FROM sakila_proxy.rental
),
inventory AS (
    SELECT * FROM sakila_proxy.inventory
)
SELECT
    r.rental_id as rental_key,
    r.customer_id as customer_key,
    i.film_id as film_key,
    r.staff_id as staff_key,
    i.store_id as store_key,
    r.rental_date,
    r.return_date,
    i.inventory_id,
    DATEDIFF('second', r.rental_date, r.return_date) as rental_duration,
    r.last_update
FROM source r
JOIN inventory i ON r.inventory_id = i.inventory_id
  ...
[0m12:02:06.154996 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:02:06.157447 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d896956-3a5c-4d1e-aed1-4df5cf8109bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d82f700d0>]}
[0m12:02:06.158457 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `adw02_stag`.`stg_rental` .................... [[32mOK[0m in 0.11s]
[0m12:02:06.159531 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rental
[0m12:02:06.160380 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m12:02:06.161407 [info ] [Thread-1 (]: 4 of 6 START sql table model `adw02_stag`.`stg_staff` .......................... [RUN]
[0m12:02:06.162061 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rental, now model.sakstar.stg_staff)
[0m12:02:06.162703 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m12:02:06.164997 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m12:02:06.165950 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m12:02:06.169299 [debug] [Thread-1 (]: Creating new relation stg_staff
[0m12:02:06.170793 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

            

    
        create table `adw02_stag`.`stg_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
          )
        
        ...
[0m12:02:06.187548 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:02:06.191144 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

    select name, type from system.columns where table = 'stg_staff'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:02:06.195674 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:02:06.202123 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff"
[0m12:02:06.202957 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_staff`
        ("staff_key", "staff_first_name", "staff_last_name", "staff_email", "staff_active", "staff_username", "staff_password", "staff_last_update", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
  ...
[0m12:02:06.223755 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:02:06.226133 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d896956-3a5c-4d1e-aed1-4df5cf8109bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d8c48d9b0>]}
[0m12:02:06.226993 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `adw02_stag`.`stg_staff` ..................... [[32mOK[0m in 0.06s]
[0m12:02:06.227782 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m12:02:06.228319 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m12:02:06.228938 [info ] [Thread-1 (]: 5 of 6 START sql table model `adw02_stag`.`stg_store` .......................... [RUN]
[0m12:02:06.229614 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_store)
[0m12:02:06.230109 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m12:02:06.232565 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m12:02:06.233504 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m12:02:06.236299 [debug] [Thread-1 (]: Creating new relation stg_store
[0m12:02:06.238366 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

            

    
        create table `adw02_stag`.`stg_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila_proxy.address a ON s.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
    JOIN sakila_proxy.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
          )
        
        ...
[0m12:02:06.263838 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:02:06.267627 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

    select name, type from system.columns where table = 'stg_store'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:02:06.272475 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:02:06.277471 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store"
[0m12:02:06.278609 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_store`
        ("store_key", "store_address", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")WITH source AS (
    SELECT * FROM sakila_proxy.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila_proxy.address a ON s.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
    JOIN sakila_proxy.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
  ...
[0m12:02:06.365769 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.09 seconds
[0m12:02:06.368142 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d896956-3a5c-4d1e-aed1-4df5cf8109bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d8aa06390>]}
[0m12:02:06.368982 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `adw02_stag`.`stg_store` ..................... [[32mOK[0m in 0.14s]
[0m12:02:06.369958 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m12:02:06.370642 [debug] [Thread-1 (]: Began running node model.sakstar.dim_customer
[0m12:02:06.371320 [info ] [Thread-1 (]: 6 of 6 START sql table model `adw02_star`.`dim_customer` ....................... [RUN]
[0m12:02:06.371928 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_store, now model.sakstar.dim_customer)
[0m12:02:06.372534 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_customer
[0m12:02:06.376018 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_customer"
[0m12:02:06.376959 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_customer
[0m12:02:06.380552 [debug] [Thread-1 (]: Creating new relation dim_customer
[0m12:02:06.382016 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

            

    
        create table `adw02_star`.`dim_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            SELECT
    customer_key,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_created,
    customer_address,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_last_update
FROM `adw02_stag`.`stg_customer`
          )
        
        ...
[0m12:02:06.394773 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:02:06.398389 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer'
    
      and database = 'adw02_star'
    
    order by position
  ...
[0m12:02:06.402839 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:02:06.406438 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_customer"
[0m12:02:06.407486 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

  
    
    
    
        
         


        insert into `adw02_star`.`dim_customer`
        ("customer_key", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_created", "customer_address", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_last_update")SELECT
    customer_key,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_created,
    customer_address,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_last_update
FROM `adw02_stag`.`stg_customer`
  ...
[0m12:02:06.415223 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:02:06.417751 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9d896956-3a5c-4d1e-aed1-4df5cf8109bb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d82febb30>]}
[0m12:02:06.418514 [info ] [Thread-1 (]: 6 of 6 OK created sql table model `adw02_star`.`dim_customer` .................. [[32mOK[0m in 0.05s]
[0m12:02:06.419270 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_customer
[0m12:02:06.421314 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:02:06.421879 [debug] [MainThread]: Connection 'model.sakstar.dim_customer' was left open.
[0m12:02:06.422324 [debug] [MainThread]: On model.sakstar.dim_customer: Close
[0m12:02:06.422979 [info ] [MainThread]: 
[0m12:02:06.423582 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 1.20 seconds (1.20s).
[0m12:02:06.425582 [debug] [MainThread]: Command end result
[0m12:02:06.484605 [info ] [MainThread]: 
[0m12:02:06.485171 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:02:06.485659 [info ] [MainThread]: 
[0m12:02:06.486124 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m12:02:06.487146 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 2.6208909, "process_in_blocks": "0", "process_kernel_time": 0.213125, "process_mem_max_rss": "143348", "process_out_blocks": "4504", "process_user_time": 3.582846}
[0m12:02:06.487755 [debug] [MainThread]: Command `dbt run` succeeded at 12:02:06.487607 after 2.62 seconds
[0m12:02:06.488394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d8c3d97f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d81503a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x710d815039b0>]}
[0m12:02:06.488916 [debug] [MainThread]: Flushing usage events
[0m12:08:59.472529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x772902186120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x772900095590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x772900095450>]}


============================== 12:08:59.476736 | e66d105a-db77-48ab-b1bc-871e357c1151 ==============================
[0m12:08:59.476736 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:08:59.477587 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'profiles_dir': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar', 'version_check': 'True', 'debug': 'False', 'log_path': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/logs', 'fail_fast': 'False', 'warn_error': 'None', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'static_parser': 'True', 'invocation_command': 'dbt run', 'target_path': 'None', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'send_anonymous_usage_stats': 'True'}
[0m12:08:59.717714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'e66d105a-db77-48ab-b1bc-871e357c1151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x772900ff9cd0>]}
[0m12:08:59.795265 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'e66d105a-db77-48ab-b1bc-871e357c1151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7728fff0f790>]}
[0m12:08:59.796135 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:08:59.920091 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:09:00.086077 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:09:00.086984 [debug] [MainThread]: Partial parsing: updated file: sakstar://models/staging/customer/stg_customer.sql
[0m12:09:00.387406 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m12:09:00.388023 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'e66d105a-db77-48ab-b1bc-871e357c1151', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7728ffee7050>]}
[0m12:09:00.622833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e66d105a-db77-48ab-b1bc-871e357c1151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7728ffa56210>]}
[0m12:09:00.756455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e66d105a-db77-48ab-b1bc-871e357c1151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7728fdeed010>]}
[0m12:09:00.757038 [info ] [MainThread]: Found 6 models, 12 data tests, 10 sources, 608 macros
[0m12:09:00.757515 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e66d105a-db77-48ab-b1bc-871e357c1151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7728ffb6fa00>]}
[0m12:09:00.760279 [info ] [MainThread]: 
[0m12:09:00.761118 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:09:00.769680 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:09:00.785911 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:09:01.138431 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:09:01.141808 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:01.174909 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:09:01.178502 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:01.181697 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__adw02_star)
[0m12:09:01.190110 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw02_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw02_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw02_star'
      

  ...
[0m12:09:01.206505 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:09:01.208422 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw02_star, now list__adw02_stag)
[0m12:09:01.210633 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw02_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw02_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw02_stag'
      

  ...
[0m12:09:01.226512 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:09:01.228456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e66d105a-db77-48ab-b1bc-871e357c1151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7728fde26510>]}
[0m12:09:01.229160 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m12:09:01.229698 [info ] [MainThread]: 
[0m12:09:01.233069 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m12:09:01.233895 [info ] [Thread-1 (]: 1 of 6 START sql table model `adw02_stag`.`stg_customer` ....................... [RUN]
[0m12:09:01.234603 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw02_stag, now model.sakstar.stg_customer)
[0m12:09:01.235100 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m12:09:01.244225 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m12:09:01.245052 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m12:09:01.274062 [debug] [Thread-1 (]: Creating new relation stg_customer
[0m12:09:01.321126 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

            

    
        create table `adw02_stag`.`stg_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
ORDER BY customer_key
          )
        
        ...
[0m12:09:01.347319 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m12:09:01.370149 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

    select name, type from system.columns where table = 'stg_customer'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:09:01.374647 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:01.380775 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m12:09:01.381630 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_customer`
        ("customer_key", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_created", "customer_address", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_last_update", "c.address_id", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_key,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
ORDER BY customer_key
  ...
[0m12:09:01.457583 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.08 seconds
[0m12:09:01.484863 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e66d105a-db77-48ab-b1bc-871e357c1151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7728fc1aeaf0>]}
[0m12:09:01.485717 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `adw02_stag`.`stg_customer` .................. [[32mOK[0m in 0.25s]
[0m12:09:01.486557 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m12:09:01.487173 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film
[0m12:09:01.487830 [info ] [Thread-1 (]: 2 of 6 START sql table model `adw02_stag`.`stg_film` ........................... [RUN]
[0m12:09:01.488490 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_film)
[0m12:09:01.489013 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film
[0m12:09:01.491366 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_film"
[0m12:09:01.492436 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_film
[0m12:09:01.495322 [debug] [Thread-1 (]: Creating new relation stg_film
[0m12:09:01.497407 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

            

    
        create table `adw02_stag`.`stg_film`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.film
)
SELECT
    f.film_id as film_key,
    f.title as film_title,
    f.description as film_description,
    f.release_year as film_release_year,
    l.name as film_language,
    CASE WHEN f.original_language_id IS NOT NULL THEN 1 ELSE 0 END as film_has_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.length as film_duration,
    f.replacement_cost as film_replacement_cost,
    f.rating as film_rating,
    f.special_features as film_special_features,
    f.last_update as film_last_update
FROM source f
JOIN sakila_proxy.language l ON f.language_id = l.language_id
          )
        
        ...
[0m12:09:01.515039 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:09:01.518645 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

    select name, type from system.columns where table = 'stg_film'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:09:01.523086 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:01.527561 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_film"
[0m12:09:01.528763 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_film`
        ("film_key", "film_title", "film_description", "film_release_year", "film_language", "film_has_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_last_update")WITH source AS (
    SELECT * FROM sakila_proxy.film
)
SELECT
    f.film_id as film_key,
    f.title as film_title,
    f.description as film_description,
    f.release_year as film_release_year,
    l.name as film_language,
    CASE WHEN f.original_language_id IS NOT NULL THEN 1 ELSE 0 END as film_has_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.length as film_duration,
    f.replacement_cost as film_replacement_cost,
    f.rating as film_rating,
    f.special_features as film_special_features,
    f.last_update as film_last_update
FROM source f
JOIN sakila_proxy.language l ON f.language_id = l.language_id
  ...
[0m12:09:01.593946 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:09:01.596429 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e66d105a-db77-48ab-b1bc-871e357c1151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7728efee9630>]}
[0m12:09:01.597244 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `adw02_stag`.`stg_film` ...................... [[32mOK[0m in 0.11s]
[0m12:09:01.598229 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film
[0m12:09:01.599027 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rental
[0m12:09:01.599712 [info ] [Thread-1 (]: 3 of 6 START sql table model `adw02_stag`.`stg_rental` ......................... [RUN]
[0m12:09:01.600506 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film, now model.sakstar.stg_rental)
[0m12:09:01.601737 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rental
[0m12:09:01.607572 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_rental"
[0m12:09:01.609092 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_rental
[0m12:09:01.614779 [debug] [Thread-1 (]: Creating new relation stg_rental
[0m12:09:01.616245 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

            

    
        create table `adw02_stag`.`stg_rental`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.rental
),
inventory AS (
    SELECT * FROM sakila_proxy.inventory
)
SELECT
    r.rental_id as rental_key,
    r.customer_id as customer_key,
    i.film_id as film_key,
    r.staff_id as staff_key,
    i.store_id as store_key,
    r.rental_date,
    r.return_date,
    i.inventory_id,
    DATEDIFF('second', r.rental_date, r.return_date) as rental_duration,
    r.last_update
FROM source r
JOIN inventory i ON r.inventory_id = i.inventory_id
          )
        
        ...
[0m12:09:01.632524 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:09:01.639660 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

    select name, type from system.columns where table = 'stg_rental'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:09:01.644466 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:01.647451 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_rental"
[0m12:09:01.648247 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_rental`
        ("rental_key", "customer_key", "film_key", "staff_key", "store_key", "rental_date", "return_date", "i.inventory_id", "rental_duration", "last_update")WITH source AS (
    SELECT * FROM sakila_proxy.rental
),
inventory AS (
    SELECT * FROM sakila_proxy.inventory
)
SELECT
    r.rental_id as rental_key,
    r.customer_id as customer_key,
    i.film_id as film_key,
    r.staff_id as staff_key,
    i.store_id as store_key,
    r.rental_date,
    r.return_date,
    i.inventory_id,
    DATEDIFF('second', r.rental_date, r.return_date) as rental_duration,
    r.last_update
FROM source r
JOIN inventory i ON r.inventory_id = i.inventory_id
  ...
[0m12:09:01.709087 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:09:01.711435 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e66d105a-db77-48ab-b1bc-871e357c1151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7728effcd650>]}
[0m12:09:01.712190 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `adw02_stag`.`stg_rental` .................... [[32mOK[0m in 0.11s]
[0m12:09:01.713026 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rental
[0m12:09:01.713594 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m12:09:01.714211 [info ] [Thread-1 (]: 4 of 6 START sql table model `adw02_stag`.`stg_staff` .......................... [RUN]
[0m12:09:01.714806 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rental, now model.sakstar.stg_staff)
[0m12:09:01.715442 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m12:09:01.717899 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m12:09:01.718729 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m12:09:01.721515 [debug] [Thread-1 (]: Creating new relation stg_staff
[0m12:09:01.723535 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

            

    
        create table `adw02_stag`.`stg_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
          )
        
        ...
[0m12:09:01.737967 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:09:01.741545 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

    select name, type from system.columns where table = 'stg_staff'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:09:01.745988 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:01.748829 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff"
[0m12:09:01.749619 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_staff`
        ("staff_key", "staff_first_name", "staff_last_name", "staff_email", "staff_active", "staff_username", "staff_password", "staff_last_update", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
  ...
[0m12:09:01.770600 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:09:01.773374 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e66d105a-db77-48ab-b1bc-871e357c1151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7728efeccc20>]}
[0m12:09:01.774197 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `adw02_stag`.`stg_staff` ..................... [[32mOK[0m in 0.06s]
[0m12:09:01.775134 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m12:09:01.775915 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m12:09:01.777003 [info ] [Thread-1 (]: 5 of 6 START sql table model `adw02_stag`.`stg_store` .......................... [RUN]
[0m12:09:01.777908 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_store)
[0m12:09:01.778590 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m12:09:01.781299 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m12:09:01.782136 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m12:09:01.785586 [debug] [Thread-1 (]: Creating new relation stg_store
[0m12:09:01.787388 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

            

    
        create table `adw02_stag`.`stg_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila_proxy.address a ON s.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
    JOIN sakila_proxy.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
          )
        
        ...
[0m12:09:01.810149 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:09:01.813746 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

    select name, type from system.columns where table = 'stg_store'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:09:01.818154 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:01.821815 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store"
[0m12:09:01.822771 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_store`
        ("store_key", "store_address", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")WITH source AS (
    SELECT * FROM sakila_proxy.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila_proxy.address a ON s.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
    JOIN sakila_proxy.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
  ...
[0m12:09:01.920888 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.10 seconds
[0m12:09:01.923367 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e66d105a-db77-48ab-b1bc-871e357c1151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7728effec410>]}
[0m12:09:01.927255 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `adw02_stag`.`stg_store` ..................... [[32mOK[0m in 0.15s]
[0m12:09:01.928296 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m12:09:01.928953 [debug] [Thread-1 (]: Began running node model.sakstar.dim_customer
[0m12:09:01.929668 [info ] [Thread-1 (]: 6 of 6 START sql table model `adw02_star`.`dim_customer` ....................... [RUN]
[0m12:09:01.930470 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_store, now model.sakstar.dim_customer)
[0m12:09:01.931517 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_customer
[0m12:09:01.935535 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_customer"
[0m12:09:01.936435 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_customer
[0m12:09:01.939551 [debug] [Thread-1 (]: Creating new relation dim_customer
[0m12:09:01.942019 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

            

    
        create table `adw02_star`.`dim_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            SELECT
    customer_key,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_created,
    customer_address,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_last_update
FROM `adw02_stag`.`stg_customer`
          )
        
        ...
[0m12:09:01.954087 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:09:01.957638 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer'
    
      and database = 'adw02_star'
    
    order by position
  ...
[0m12:09:01.963202 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:09:01.967080 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_customer"
[0m12:09:01.968013 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

  
    
    
    
        
         


        insert into `adw02_star`.`dim_customer`
        ("customer_key", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_created", "customer_address", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_last_update")SELECT
    customer_key,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_created,
    customer_address,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_last_update
FROM `adw02_stag`.`stg_customer`
  ...
[0m12:09:01.975765 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:09:01.978179 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e66d105a-db77-48ab-b1bc-871e357c1151', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7728ee52cd10>]}
[0m12:09:01.978997 [info ] [Thread-1 (]: 6 of 6 OK created sql table model `adw02_star`.`dim_customer` .................. [[32mOK[0m in 0.05s]
[0m12:09:01.979855 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_customer
[0m12:09:01.981565 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:09:01.982063 [debug] [MainThread]: Connection 'model.sakstar.dim_customer' was left open.
[0m12:09:01.982640 [debug] [MainThread]: On model.sakstar.dim_customer: Close
[0m12:09:01.983332 [info ] [MainThread]: 
[0m12:09:01.984007 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 1.22 seconds (1.22s).
[0m12:09:01.986019 [debug] [MainThread]: Command end result
[0m12:09:02.036982 [info ] [MainThread]: 
[0m12:09:02.037713 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:09:02.038170 [info ] [MainThread]: 
[0m12:09:02.038740 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m12:09:02.039896 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 2.6346862, "process_in_blocks": "0", "process_kernel_time": 0.225826, "process_mem_max_rss": "143012", "process_out_blocks": "4504", "process_user_time": 3.655923}
[0m12:09:02.040521 [debug] [MainThread]: Command `dbt run` succeeded at 12:09:02.040373 after 2.64 seconds
[0m12:09:02.041000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x772901d179b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7728ee5678f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7728ee567890>]}
[0m12:09:02.041609 [debug] [MainThread]: Flushing usage events
[0m12:26:16.194830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b26488a120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b2627a9590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b2627a9450>]}


============================== 12:26:16.197535 | a0acd021-e88c-40de-881c-98f6a0c1d0c5 ==============================
[0m12:26:16.197535 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:26:16.198133 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'write_json': 'True', 'log_cache_events': 'False', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'version_check': 'True', 'debug': 'False', 'log_path': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/logs', 'fail_fast': 'False', 'profiles_dir': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar', 'use_colors': 'True', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'no_print': 'None', 'log_format': 'default', 'introspect': 'True', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'static_parser': 'True', 'target_path': 'None', 'invocation_command': 'dbt run', 'send_anonymous_usage_stats': 'True'}
[0m12:26:16.345775 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': 'a0acd021-e88c-40de-881c-98f6a0c1d0c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b2637ddcd0>]}
[0m12:26:16.394585 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': 'a0acd021-e88c-40de-881c-98f6a0c1d0c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b26261b790>]}
[0m12:26:16.395228 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:26:16.476134 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:26:16.586876 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m12:26:16.587509 [debug] [MainThread]: Partial parsing: updated file: sakstar://models/marts/dim/dim_customer/dim_customer.sql
[0m12:26:16.587989 [debug] [MainThread]: Partial parsing: updated file: sakstar://models/staging/customer/stg_customer.sql
[0m12:26:16.786001 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m12:26:16.786456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': 'a0acd021-e88c-40de-881c-98f6a0c1d0c5', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b2625f3750>]}
[0m12:26:16.945267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a0acd021-e88c-40de-881c-98f6a0c1d0c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b2623536b0>]}
[0m12:26:17.037639 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a0acd021-e88c-40de-881c-98f6a0c1d0c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b2605dd0f0>]}
[0m12:26:17.038049 [info ] [MainThread]: Found 6 models, 12 data tests, 10 sources, 608 macros
[0m12:26:17.038411 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a0acd021-e88c-40de-881c-98f6a0c1d0c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b26056e270>]}
[0m12:26:17.040401 [info ] [MainThread]: 
[0m12:26:17.040933 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:26:17.046815 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:26:17.058195 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:26:17.299169 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:26:17.301753 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:26:17.323375 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:26:17.326441 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:26:17.329163 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__adw02_star)
[0m12:26:17.334432 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw02_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw02_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw02_star'
      

  ...
[0m12:26:17.345743 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:26:17.347303 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw02_star, now list__adw02_stag)
[0m12:26:17.349005 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw02_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw02_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw02_stag'
      

  ...
[0m12:26:17.360055 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:26:17.361421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a0acd021-e88c-40de-881c-98f6a0c1d0c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b260562390>]}
[0m12:26:17.361913 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m12:26:17.362232 [info ] [MainThread]: 
[0m12:26:17.364354 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m12:26:17.364865 [info ] [Thread-1 (]: 1 of 6 START sql table model `adw02_stag`.`stg_customer` ....................... [RUN]
[0m12:26:17.365361 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw02_stag, now model.sakstar.stg_customer)
[0m12:26:17.365705 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m12:26:17.371917 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m12:26:17.372465 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m12:26:17.389715 [debug] [Thread-1 (]: Creating new relation stg_customer
[0m12:26:17.419701 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

            

    
        create table `adw02_stag`.`stg_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_id,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.district as customer_district,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
ORDER BY customer_id
          )
        
        ...
[0m12:26:17.435487 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:26:17.450206 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

    select name, type from system.columns where table = 'stg_customer'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:26:17.453673 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:26:17.457692 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m12:26:17.458443 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_customer`
        ("customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_created", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_last_update", "c.address_id", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_id,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.district as customer_district,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
ORDER BY customer_id
  ...
[0m12:26:17.513565 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:26:17.533228 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0acd021-e88c-40de-881c-98f6a0c1d0c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b22e881de0>]}
[0m12:26:17.534165 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `adw02_stag`.`stg_customer` .................. [[32mOK[0m in 0.17s]
[0m12:26:17.534782 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m12:26:17.535159 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film
[0m12:26:17.535845 [info ] [Thread-1 (]: 2 of 6 START sql table model `adw02_stag`.`stg_film` ........................... [RUN]
[0m12:26:17.536258 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_film)
[0m12:26:17.536592 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film
[0m12:26:17.538265 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_film"
[0m12:26:17.538831 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_film
[0m12:26:17.540793 [debug] [Thread-1 (]: Creating new relation stg_film
[0m12:26:17.542164 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

            

    
        create table `adw02_stag`.`stg_film`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.film
)
SELECT
    f.film_id as film_key,
    f.title as film_title,
    f.description as film_description,
    f.release_year as film_release_year,
    l.name as film_language,
    CASE WHEN f.original_language_id IS NOT NULL THEN 1 ELSE 0 END as film_has_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.length as film_duration,
    f.replacement_cost as film_replacement_cost,
    f.rating as film_rating,
    f.special_features as film_special_features,
    f.last_update as film_last_update
FROM source f
JOIN sakila_proxy.language l ON f.language_id = l.language_id
          )
        
        ...
[0m12:26:17.556558 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:26:17.558963 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

    select name, type from system.columns where table = 'stg_film'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:26:17.562386 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:26:17.564665 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_film"
[0m12:26:17.565263 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_film`
        ("film_key", "film_title", "film_description", "film_release_year", "film_language", "film_has_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_last_update")WITH source AS (
    SELECT * FROM sakila_proxy.film
)
SELECT
    f.film_id as film_key,
    f.title as film_title,
    f.description as film_description,
    f.release_year as film_release_year,
    l.name as film_language,
    CASE WHEN f.original_language_id IS NOT NULL THEN 1 ELSE 0 END as film_has_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.length as film_duration,
    f.replacement_cost as film_replacement_cost,
    f.rating as film_rating,
    f.special_features as film_special_features,
    f.last_update as film_last_update
FROM source f
JOIN sakila_proxy.language l ON f.language_id = l.language_id
  ...
[0m12:26:17.593137 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m12:26:17.594770 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0acd021-e88c-40de-881c-98f6a0c1d0c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b22e64e210>]}
[0m12:26:17.595282 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `adw02_stag`.`stg_film` ...................... [[32mOK[0m in 0.06s]
[0m12:26:17.595805 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film
[0m12:26:17.596168 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rental
[0m12:26:17.596583 [info ] [Thread-1 (]: 3 of 6 START sql table model `adw02_stag`.`stg_rental` ......................... [RUN]
[0m12:26:17.596972 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film, now model.sakstar.stg_rental)
[0m12:26:17.597287 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rental
[0m12:26:17.599197 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_rental"
[0m12:26:17.599994 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_rental
[0m12:26:17.601834 [debug] [Thread-1 (]: Creating new relation stg_rental
[0m12:26:17.603056 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

            

    
        create table `adw02_stag`.`stg_rental`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.rental
),
inventory AS (
    SELECT * FROM sakila_proxy.inventory
)
SELECT
    r.rental_id as rental_key,
    r.customer_id as customer_key,
    i.film_id as film_key,
    r.staff_id as staff_key,
    i.store_id as store_key,
    r.rental_date,
    r.return_date,
    i.inventory_id,
    DATEDIFF('second', r.rental_date, r.return_date) as rental_duration,
    r.last_update
FROM source r
JOIN inventory i ON r.inventory_id = i.inventory_id
          )
        
        ...
[0m12:26:17.617152 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:26:17.622057 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

    select name, type from system.columns where table = 'stg_rental'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:26:17.625661 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:26:17.627655 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_rental"
[0m12:26:17.628180 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_rental`
        ("rental_key", "customer_key", "film_key", "staff_key", "store_key", "rental_date", "return_date", "i.inventory_id", "rental_duration", "last_update")WITH source AS (
    SELECT * FROM sakila_proxy.rental
),
inventory AS (
    SELECT * FROM sakila_proxy.inventory
)
SELECT
    r.rental_id as rental_key,
    r.customer_id as customer_key,
    i.film_id as film_key,
    r.staff_id as staff_key,
    i.store_id as store_key,
    r.rental_date,
    r.return_date,
    i.inventory_id,
    DATEDIFF('second', r.rental_date, r.return_date) as rental_duration,
    r.last_update
FROM source r
JOIN inventory i ON r.inventory_id = i.inventory_id
  ...
[0m12:26:17.670538 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m12:26:17.672109 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0acd021-e88c-40de-881c-98f6a0c1d0c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b22e6f4bd0>]}
[0m12:26:17.672613 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `adw02_stag`.`stg_rental` .................... [[32mOK[0m in 0.08s]
[0m12:26:17.673126 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rental
[0m12:26:17.673495 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m12:26:17.674009 [info ] [Thread-1 (]: 4 of 6 START sql table model `adw02_stag`.`stg_staff` .......................... [RUN]
[0m12:26:17.674421 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rental, now model.sakstar.stg_staff)
[0m12:26:17.674742 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m12:26:17.676283 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m12:26:17.676887 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m12:26:17.678739 [debug] [Thread-1 (]: Creating new relation stg_staff
[0m12:26:17.680189 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

            

    
        create table `adw02_stag`.`stg_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
          )
        
        ...
[0m12:26:17.692005 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:26:17.694431 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

    select name, type from system.columns where table = 'stg_staff'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:26:17.697731 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:26:17.699982 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff"
[0m12:26:17.700560 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_staff`
        ("staff_key", "staff_first_name", "staff_last_name", "staff_email", "staff_active", "staff_username", "staff_password", "staff_last_update", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
  ...
[0m12:26:17.714738 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:26:17.716401 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0acd021-e88c-40de-881c-98f6a0c1d0c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b22e65cc20>]}
[0m12:26:17.716903 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `adw02_stag`.`stg_staff` ..................... [[32mOK[0m in 0.04s]
[0m12:26:17.717592 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m12:26:17.717962 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m12:26:17.718434 [info ] [Thread-1 (]: 5 of 6 START sql table model `adw02_stag`.`stg_store` .......................... [RUN]
[0m12:26:17.718827 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_store)
[0m12:26:17.719142 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m12:26:17.721537 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m12:26:17.722176 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m12:26:17.725043 [debug] [Thread-1 (]: Creating new relation stg_store
[0m12:26:17.726314 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

            

    
        create table `adw02_stag`.`stg_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila_proxy.address a ON s.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
    JOIN sakila_proxy.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
          )
        
        ...
[0m12:26:17.745050 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:26:17.747994 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

    select name, type from system.columns where table = 'stg_store'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:26:17.751613 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:26:17.753713 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store"
[0m12:26:17.754329 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_store`
        ("store_key", "store_address", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")WITH source AS (
    SELECT * FROM sakila_proxy.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila_proxy.address a ON s.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
    JOIN sakila_proxy.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
  ...
[0m12:26:17.812025 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:26:17.813609 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0acd021-e88c-40de-881c-98f6a0c1d0c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b22e7537d0>]}
[0m12:26:17.814120 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `adw02_stag`.`stg_store` ..................... [[32mOK[0m in 0.09s]
[0m12:26:17.814648 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m12:26:17.815020 [debug] [Thread-1 (]: Began running node model.sakstar.dim_customer
[0m12:26:17.815500 [info ] [Thread-1 (]: 6 of 6 START sql table model `adw02_star`.`dim_customer` ....................... [RUN]
[0m12:26:17.815879 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_store, now model.sakstar.dim_customer)
[0m12:26:17.816205 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_customer
[0m12:26:17.818513 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_customer"
[0m12:26:17.819105 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_customer
[0m12:26:17.821194 [debug] [Thread-1 (]: Creating new relation dim_customer
[0m12:26:17.822640 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

            

    
        create table `adw02_star`.`dim_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            SELECT
    MD5(CONCAT(customer_first_name, customer_last_name, customer_email)) AS customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_created,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_last_update
FROM `adw02_stag`.`stg_customer`
          )
        
        ...
[0m12:26:17.832519 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:26:17.834848 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer'
    
      and database = 'adw02_star'
    
    order by position
  ...
[0m12:26:17.838106 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:26:17.840327 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_customer"
[0m12:26:17.840878 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

  
    
    
    
        
         


        insert into `adw02_star`.`dim_customer`
        ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_created", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_last_update")SELECT
    MD5(CONCAT(customer_first_name, customer_last_name, customer_email)) AS customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_created,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_last_update
FROM `adw02_stag`.`stg_customer`
  ...
[0m12:26:17.846510 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:26:17.848071 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a0acd021-e88c-40de-881c-98f6a0c1d0c5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b22e660e30>]}
[0m12:26:17.848589 [info ] [Thread-1 (]: 6 of 6 OK created sql table model `adw02_star`.`dim_customer` .................. [[32mOK[0m in 0.03s]
[0m12:26:17.849119 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_customer
[0m12:26:17.850295 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:26:17.850642 [debug] [MainThread]: Connection 'model.sakstar.dim_customer' was left open.
[0m12:26:17.850927 [debug] [MainThread]: On model.sakstar.dim_customer: Close
[0m12:26:17.851476 [info ] [MainThread]: 
[0m12:26:17.851958 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 0.81 seconds (0.81s).
[0m12:26:17.853547 [debug] [MainThread]: Command end result
[0m12:26:17.885930 [info ] [MainThread]: 
[0m12:26:17.886359 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:26:17.886664 [info ] [MainThread]: 
[0m12:26:17.886973 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m12:26:17.887699 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.7319728, "process_in_blocks": "0", "process_kernel_time": 0.147513, "process_mem_max_rss": "142964", "process_out_blocks": "4504", "process_user_time": 2.331611}
[0m12:26:17.888090 [debug] [MainThread]: Command `dbt run` succeeded at 12:26:17.887997 after 1.73 seconds
[0m12:26:17.888499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b264464a70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b22cc939b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x79b22cc93950>]}
[0m12:26:17.888870 [debug] [MainThread]: Flushing usage events
[0m12:30:05.182641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b79cb9e120>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b79aac1590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b79aac1450>]}


============================== 12:30:05.185481 | 97754b20-508e-4af2-bfb6-7b5b5118dea2 ==============================
[0m12:30:05.185481 [info ] [MainThread]: Running with dbt=1.8.9
[0m12:30:05.186000 [debug] [MainThread]: running dbt with arguments {'printer_width': '80', 'indirect_selection': 'eager', 'log_cache_events': 'False', 'write_json': 'True', 'partial_parse': 'True', 'cache_selected_only': 'False', 'warn_error': 'None', 'fail_fast': 'False', 'version_check': 'True', 'log_path': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar/logs', 'debug': 'False', 'profiles_dir': '/home/sergon/Documents/semestre7/ADW/ADW-EE2/Notebook/dbtSakStar', 'use_colors': 'True', 'use_experimental_parser': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'warn_error_options': 'WarnErrorOptions(include=[], exclude=[])', 'invocation_command': 'dbt run', 'static_parser': 'True', 'log_format': 'default', 'target_path': 'None', 'introspect': 'True', 'send_anonymous_usage_stats': 'True'}
[0m12:30:05.331465 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'project_id', 'label': '97754b20-508e-4af2-bfb6-7b5b5118dea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b79baf5cd0>]}
[0m12:30:05.384398 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'adapter_info', 'label': '97754b20-508e-4af2-bfb6-7b5b5118dea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b79a933790>]}
[0m12:30:05.385012 [info ] [MainThread]: Registered adapter: clickhouse=1.8.9
[0m12:30:05.469006 [debug] [MainThread]: checksum: 132857a23e9d07220246854f7763165174ce9b737cfc7867629ace4294e520b1, vars: {}, profile: , target: , version: 1.8.9
[0m12:30:05.573911 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m12:30:05.574524 [debug] [MainThread]: Partial parsing: updated file: sakstar://models/marts/dim/dim_customer/dim_customer.yml
[0m12:30:05.767421 [warn ] [MainThread]: [[33mWARNING[0m]: Deprecated functionality
The `tests` config has been renamed to `data_tests`. Please see
https://docs.getdbt.com/docs/build/data-tests#new-data_tests-syntax for more
information.
[0m12:30:05.767881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'deprecation', 'label': '97754b20-508e-4af2-bfb6-7b5b5118dea2', 'property_': 'warn', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b79a90b750>]}
[0m12:30:05.920828 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '97754b20-508e-4af2-bfb6-7b5b5118dea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b79a46a300>]}
[0m12:30:06.011866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '97754b20-508e-4af2-bfb6-7b5b5118dea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b798af9010>]}
[0m12:30:06.012254 [info ] [MainThread]: Found 6 models, 12 data tests, 10 sources, 608 macros
[0m12:30:06.012634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '97754b20-508e-4af2-bfb6-7b5b5118dea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b798bffa00>]}
[0m12:30:06.014493 [info ] [MainThread]: 
[0m12:30:06.014986 [debug] [MainThread]: Acquiring new clickhouse connection 'master'
[0m12:30:06.020839 [debug] [ThreadPool]: Acquiring new clickhouse connection 'list_'
[0m12:30:06.029577 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:30:06.270944 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:30:06.273507 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:30:06.295312 [debug] [ThreadPool]: dbt_clickhouse adapter: On list_: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list_"} */

    select name from system.databases
  ...
[0m12:30:06.298455 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:30:06.300518 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list_, now list__adw02_star)
[0m12:30:06.306093 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw02_star: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw02_star"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw02_star'
      

  ...
[0m12:30:06.317920 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:30:06.319236 [debug] [ThreadPool]: Re-using an available connection from the pool (formerly list__adw02_star, now list__adw02_stag)
[0m12:30:06.320826 [debug] [ThreadPool]: dbt_clickhouse adapter: On list__adw02_stag: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "connection_name": "list__adw02_stag"} */
select
      t.name as name,
      t.database as schema,
      multiIf(
        engine in ('MaterializedView', 'View'), 'view',
        engine = 'Dictionary', 'dictionary',
        'table'
      ) as type,
      db.engine as db_engine,0 as is_on_cluster
          from system.tables as t join system.databases as db on t.database = db.name
        where schema = 'adw02_stag'
      

  ...
[0m12:30:06.332532 [debug] [ThreadPool]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:30:06.334248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '97754b20-508e-4af2-bfb6-7b5b5118dea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b798c22810>]}
[0m12:30:06.334761 [info ] [MainThread]: Concurrency: 1 threads (target='clickhouse')
[0m12:30:06.335075 [info ] [MainThread]: 
[0m12:30:06.337268 [debug] [Thread-1 (]: Began running node model.sakstar.stg_customer
[0m12:30:06.337774 [info ] [Thread-1 (]: 1 of 6 START sql table model `adw02_stag`.`stg_customer` ....................... [RUN]
[0m12:30:06.338208 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly list__adw02_stag, now model.sakstar.stg_customer)
[0m12:30:06.338630 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_customer
[0m12:30:06.344578 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_customer"
[0m12:30:06.345164 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_customer
[0m12:30:06.361991 [debug] [Thread-1 (]: Creating new relation stg_customer
[0m12:30:06.391767 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

            

    
        create table `adw02_stag`.`stg_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_id,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.district as customer_district,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
ORDER BY customer_id
          )
        
        ...
[0m12:30:06.411012 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:30:06.457700 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

    select name, type from system.columns where table = 'stg_customer'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:30:06.462228 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:30:06.467449 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_customer"
[0m12:30:06.468121 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_customer"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_customer`
        ("customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_created", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_last_update", "c.address_id", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.customer
),
joined AS (
    SELECT
        c.customer_id as customer_id,
        c.first_name as customer_first_name,
        c.last_name as customer_last_name,
        c.email as customer_email,
        c.active as customer_active,
        c.create_date as customer_created,
        a.address as customer_address,
        a.district as customer_district,
        a.postal_code as customer_postal_code,
        a.phone as customer_phone_number,
        ci.city as customer_city,
        co.country as customer_country,
        c.last_update as customer_last_update,
        c.address_id,
        c.store_id
    FROM source c
    JOIN sakila_proxy.address a ON c.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
)
SELECT * FROM joined
ORDER BY customer_id
  ...
[0m12:30:06.523171 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.05 seconds
[0m12:30:06.543564 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97754b20-508e-4af2-bfb6-7b5b5118dea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b79a291ff0>]}
[0m12:30:06.544172 [info ] [Thread-1 (]: 1 of 6 OK created sql table model `adw02_stag`.`stg_customer` .................. [[32mOK[0m in 0.20s]
[0m12:30:06.544853 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_customer
[0m12:30:06.545419 [debug] [Thread-1 (]: Began running node model.sakstar.stg_film
[0m12:30:06.545859 [info ] [Thread-1 (]: 2 of 6 START sql table model `adw02_stag`.`stg_film` ........................... [RUN]
[0m12:30:06.546329 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_customer, now model.sakstar.stg_film)
[0m12:30:06.546840 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_film
[0m12:30:06.548749 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_film"
[0m12:30:06.549479 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_film
[0m12:30:06.551564 [debug] [Thread-1 (]: Creating new relation stg_film
[0m12:30:06.553261 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

            

    
        create table `adw02_stag`.`stg_film`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.film
)
SELECT
    f.film_id as film_key,
    f.title as film_title,
    f.description as film_description,
    f.release_year as film_release_year,
    l.name as film_language,
    CASE WHEN f.original_language_id IS NOT NULL THEN 1 ELSE 0 END as film_has_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.length as film_duration,
    f.replacement_cost as film_replacement_cost,
    f.rating as film_rating,
    f.special_features as film_special_features,
    f.last_update as film_last_update
FROM source f
JOIN sakila_proxy.language l ON f.language_id = l.language_id
          )
        
        ...
[0m12:30:06.567803 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:30:06.570371 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

    select name, type from system.columns where table = 'stg_film'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:30:06.573612 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:30:06.575821 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_film"
[0m12:30:06.576374 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_film: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_film"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_film`
        ("film_key", "film_title", "film_description", "film_release_year", "film_language", "film_has_original_language", "film_rental_duration", "film_rental_rate", "film_duration", "film_replacement_cost", "film_rating", "film_special_features", "film_last_update")WITH source AS (
    SELECT * FROM sakila_proxy.film
)
SELECT
    f.film_id as film_key,
    f.title as film_title,
    f.description as film_description,
    f.release_year as film_release_year,
    l.name as film_language,
    CASE WHEN f.original_language_id IS NOT NULL THEN 1 ELSE 0 END as film_has_original_language,
    f.rental_duration as film_rental_duration,
    f.rental_rate as film_rental_rate,
    f.length as film_duration,
    f.replacement_cost as film_replacement_cost,
    f.rating as film_rating,
    f.special_features as film_special_features,
    f.last_update as film_last_update
FROM source f
JOIN sakila_proxy.language l ON f.language_id = l.language_id
  ...
[0m12:30:06.605056 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.03 seconds
[0m12:30:06.606777 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97754b20-508e-4af2-bfb6-7b5b5118dea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b792909590>]}
[0m12:30:06.607283 [info ] [Thread-1 (]: 2 of 6 OK created sql table model `adw02_stag`.`stg_film` ...................... [[32mOK[0m in 0.06s]
[0m12:30:06.607947 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_film
[0m12:30:06.608482 [debug] [Thread-1 (]: Began running node model.sakstar.stg_rental
[0m12:30:06.609024 [info ] [Thread-1 (]: 3 of 6 START sql table model `adw02_stag`.`stg_rental` ......................... [RUN]
[0m12:30:06.609527 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_film, now model.sakstar.stg_rental)
[0m12:30:06.609964 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_rental
[0m12:30:06.612039 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_rental"
[0m12:30:06.612621 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_rental
[0m12:30:06.614482 [debug] [Thread-1 (]: Creating new relation stg_rental
[0m12:30:06.615459 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

            

    
        create table `adw02_stag`.`stg_rental`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.rental
),
inventory AS (
    SELECT * FROM sakila_proxy.inventory
)
SELECT
    r.rental_id as rental_key,
    r.customer_id as customer_key,
    i.film_id as film_key,
    r.staff_id as staff_key,
    i.store_id as store_key,
    r.rental_date,
    r.return_date,
    i.inventory_id,
    DATEDIFF('second', r.rental_date, r.return_date) as rental_duration,
    r.last_update
FROM source r
JOIN inventory i ON r.inventory_id = i.inventory_id
          )
        
        ...
[0m12:30:06.629106 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:30:06.631849 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

    select name, type from system.columns where table = 'stg_rental'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:30:06.635567 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:30:06.637527 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_rental"
[0m12:30:06.638043 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_rental: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_rental"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_rental`
        ("rental_key", "customer_key", "film_key", "staff_key", "store_key", "rental_date", "return_date", "i.inventory_id", "rental_duration", "last_update")WITH source AS (
    SELECT * FROM sakila_proxy.rental
),
inventory AS (
    SELECT * FROM sakila_proxy.inventory
)
SELECT
    r.rental_id as rental_key,
    r.customer_id as customer_key,
    i.film_id as film_key,
    r.staff_id as staff_key,
    i.store_id as store_key,
    r.rental_date,
    r.return_date,
    i.inventory_id,
    DATEDIFF('second', r.rental_date, r.return_date) as rental_duration,
    r.last_update
FROM source r
JOIN inventory i ON r.inventory_id = i.inventory_id
  ...
[0m12:30:06.679593 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.04 seconds
[0m12:30:06.681341 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97754b20-508e-4af2-bfb6-7b5b5118dea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b7929bc8d0>]}
[0m12:30:06.682044 [info ] [Thread-1 (]: 3 of 6 OK created sql table model `adw02_stag`.`stg_rental` .................... [[32mOK[0m in 0.07s]
[0m12:30:06.682710 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_rental
[0m12:30:06.683269 [debug] [Thread-1 (]: Began running node model.sakstar.stg_staff
[0m12:30:06.683771 [info ] [Thread-1 (]: 4 of 6 START sql table model `adw02_stag`.`stg_staff` .......................... [RUN]
[0m12:30:06.684170 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_rental, now model.sakstar.stg_staff)
[0m12:30:06.684602 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_staff
[0m12:30:06.686228 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_staff"
[0m12:30:06.686794 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_staff
[0m12:30:06.688689 [debug] [Thread-1 (]: Creating new relation stg_staff
[0m12:30:06.690106 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

            

    
        create table `adw02_stag`.`stg_staff`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
          )
        
        ...
[0m12:30:06.701628 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:30:06.704074 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

    select name, type from system.columns where table = 'stg_staff'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:30:06.707535 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:30:06.709442 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_staff"
[0m12:30:06.709979 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_staff: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_staff"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_staff`
        ("staff_key", "staff_first_name", "staff_last_name", "staff_email", "staff_active", "staff_username", "staff_password", "staff_last_update", "store_id")WITH source AS (
    SELECT * FROM sakila_proxy.staff
)
SELECT
    staff_id as staff_key,
    first_name as staff_first_name,
    last_name as staff_last_name,
    email as staff_email,
    active as staff_active,
    username as staff_username,
    password as staff_password,
    last_update as staff_last_update,
    store_id as store_id
FROM source
  ...
[0m12:30:06.723878 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:30:06.725451 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97754b20-508e-4af2-bfb6-7b5b5118dea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b79a301c50>]}
[0m12:30:06.725957 [info ] [Thread-1 (]: 4 of 6 OK created sql table model `adw02_stag`.`stg_staff` ..................... [[32mOK[0m in 0.04s]
[0m12:30:06.726468 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_staff
[0m12:30:06.726831 [debug] [Thread-1 (]: Began running node model.sakstar.stg_store
[0m12:30:06.727360 [info ] [Thread-1 (]: 5 of 6 START sql table model `adw02_stag`.`stg_store` .......................... [RUN]
[0m12:30:06.727749 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_staff, now model.sakstar.stg_store)
[0m12:30:06.728067 [debug] [Thread-1 (]: Began compiling node model.sakstar.stg_store
[0m12:30:06.729586 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.stg_store"
[0m12:30:06.730228 [debug] [Thread-1 (]: Began executing node model.sakstar.stg_store
[0m12:30:06.736026 [debug] [Thread-1 (]: Creating new relation stg_store
[0m12:30:06.737059 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

            

    
        create table `adw02_stag`.`stg_store`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            WITH source AS (
    SELECT * FROM sakila_proxy.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila_proxy.address a ON s.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
    JOIN sakila_proxy.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
          )
        
        ...
[0m12:30:06.754428 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.02 seconds
[0m12:30:06.756968 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

    select name, type from system.columns where table = 'stg_store'
    
      and database = 'adw02_stag'
    
    order by position
  ...
[0m12:30:06.760251 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:30:06.762190 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.stg_store"
[0m12:30:06.762745 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.stg_store: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.stg_store"} */

  
    
    
    
        
         


        insert into `adw02_stag`.`stg_store`
        ("store_key", "store_address", "store_postal_code", "store_phone_number", "store_city", "store_country", "store_manager_staff_id", "store_manager_first_name", "store_manager_last_name", "store_last_update")WITH source AS (
    SELECT * FROM sakila_proxy.store
),
joined AS (
    SELECT
        s.store_id as store_key,
        a.address as store_address,
        a.postal_code as store_postal_code,
        a.phone as store_phone_number,
        ci.city as store_city,
        co.country as store_country,
        s.manager_staff_id as store_manager_staff_id,
        stf.first_name as store_manager_first_name,
        stf.last_name as store_manager_last_name,
        s.last_update as store_last_update
    FROM source s
    JOIN sakila_proxy.address a ON s.address_id = a.address_id
    JOIN sakila_proxy.city ci ON a.city_id = ci.city_id
    JOIN sakila_proxy.country co ON ci.country_id = co.country_id
    JOIN sakila_proxy.staff stf ON s.manager_staff_id = stf.staff_id
)
SELECT * FROM joined
  ...
[0m12:30:06.819069 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.06 seconds
[0m12:30:06.820641 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97754b20-508e-4af2-bfb6-7b5b5118dea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b792a2b2f0>]}
[0m12:30:06.821146 [info ] [Thread-1 (]: 5 of 6 OK created sql table model `adw02_stag`.`stg_store` ..................... [[32mOK[0m in 0.09s]
[0m12:30:06.821777 [debug] [Thread-1 (]: Finished running node model.sakstar.stg_store
[0m12:30:06.822362 [debug] [Thread-1 (]: Began running node model.sakstar.dim_customer
[0m12:30:06.822783 [info ] [Thread-1 (]: 6 of 6 START sql table model `adw02_star`.`dim_customer` ....................... [RUN]
[0m12:30:06.823293 [debug] [Thread-1 (]: Re-using an available connection from the pool (formerly model.sakstar.stg_store, now model.sakstar.dim_customer)
[0m12:30:06.823787 [debug] [Thread-1 (]: Began compiling node model.sakstar.dim_customer
[0m12:30:06.826194 [debug] [Thread-1 (]: Writing injected SQL for node "model.sakstar.dim_customer"
[0m12:30:06.826757 [debug] [Thread-1 (]: Began executing node model.sakstar.dim_customer
[0m12:30:06.828625 [debug] [Thread-1 (]: Creating new relation dim_customer
[0m12:30:06.830090 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

            

    
        create table `adw02_star`.`dim_customer`
        
  
        
  engine = MergeTree()
        
      order by (tuple())
        
        
        
        
                    -- end_of_sql
                    SETTINGS  replicated_deduplication_window=0

                    
            empty
          as (
            SELECT
    MD5(CONCAT(customer_first_name, customer_last_name, customer_email)) AS customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_created,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_last_update
FROM `adw02_stag`.`stg_customer`
          )
        
        ...
[0m12:30:06.840478 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:30:06.842859 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

    select name, type from system.columns where table = 'dim_customer'
    
      and database = 'adw02_star'
    
    order by position
  ...
[0m12:30:06.846427 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.00 seconds
[0m12:30:06.848684 [debug] [Thread-1 (]: Writing runtime sql for node "model.sakstar.dim_customer"
[0m12:30:06.849220 [debug] [Thread-1 (]: dbt_clickhouse adapter: On model.sakstar.dim_customer: /* {"app": "dbt", "dbt_version": "1.8.9", "profile_name": "sak_profile", "target_name": "clickhouse", "node_id": "model.sakstar.dim_customer"} */

  
    
    
    
        
         


        insert into `adw02_star`.`dim_customer`
        ("customer_skey", "customer_id", "customer_first_name", "customer_last_name", "customer_email", "customer_active", "customer_created", "customer_address", "customer_district", "customer_postal_code", "customer_phone_number", "customer_city", "customer_country", "customer_last_update")SELECT
    MD5(CONCAT(customer_first_name, customer_last_name, customer_email)) AS customer_skey,
    customer_id,
    customer_first_name,
    customer_last_name,
    customer_email,
    customer_active,
    customer_created,
    customer_address,
    customer_district,
    customer_postal_code,
    customer_phone_number,
    customer_city,
    customer_country,
    customer_last_update
FROM `adw02_stag`.`stg_customer`
  ...
[0m12:30:06.854878 [debug] [Thread-1 (]: dbt_clickhouse adapter: SQL status: OK in 0.01 seconds
[0m12:30:06.856560 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97754b20-508e-4af2-bfb6-7b5b5118dea2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b790f4cf50>]}
[0m12:30:06.857074 [info ] [Thread-1 (]: 6 of 6 OK created sql table model `adw02_star`.`dim_customer` .................. [[32mOK[0m in 0.03s]
[0m12:30:06.857742 [debug] [Thread-1 (]: Finished running node model.sakstar.dim_customer
[0m12:30:06.859060 [debug] [MainThread]: Connection 'master' was properly closed.
[0m12:30:06.859351 [debug] [MainThread]: Connection 'model.sakstar.dim_customer' was left open.
[0m12:30:06.859637 [debug] [MainThread]: On model.sakstar.dim_customer: Close
[0m12:30:06.860029 [info ] [MainThread]: 
[0m12:30:06.860340 [info ] [MainThread]: Finished running 6 table models in 0 hours 0 minutes and 0.85 seconds (0.85s).
[0m12:30:06.861631 [debug] [MainThread]: Command end result
[0m12:30:06.895288 [info ] [MainThread]: 
[0m12:30:06.895674 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:30:06.895959 [info ] [MainThread]: 
[0m12:30:06.896259 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
[0m12:30:06.896928 [debug] [MainThread]: Resource report: {"command_name": "run", "command_success": true, "command_wall_clock_time": 1.7547084, "process_in_blocks": "0", "process_kernel_time": 0.151679, "process_mem_max_rss": "143248", "process_out_blocks": "4504", "process_user_time": 2.374687}
[0m12:30:06.897290 [debug] [MainThread]: Command `dbt run` succeeded at 12:30:06.897202 after 1.76 seconds
[0m12:30:06.897610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b79cdfe8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b790f4fb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x74b790f4fb30>]}
[0m12:30:06.897925 [debug] [MainThread]: Flushing usage events
